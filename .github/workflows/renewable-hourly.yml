# file: .github/workflows/renewable-hourly.yml
name: renewable-hourly-update

on:
  workflow_dispatch:
    inputs:
      force_run:
        description: 'Force full pipeline run (skip freshness check)'
        type: boolean
        default: false
  schedule:
    - cron: "17 * * * *"

permissions:
  contents: write

concurrency:
  group: renewable-hourly
  cancel-in-progress: true

jobs:
  update:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    env:
      EIA_API_KEY: ${{ secrets.EIA_API_KEY }}
      FORCE_RUN: ${{ github.event_name == 'workflow_dispatch' && inputs.force_run && 'true' || 'false' }}
      RENEWABLE_REGIONS: "CALI,ERCO,MISO"
      RENEWABLE_FUELS: "WND,SUN"
      LOOKBACK_DAYS: "30"
      RENEWABLE_HORIZON: "24"
      RENEWABLE_CV_WINDOWS: "2"
      RENEWABLE_CV_STEP_SIZE: "168"
      MAX_LAG_HOURS: "48"  # EIA publishes hourly data with 12-24h delay
      MAX_MISSING_RATIO: "0.02"
      RENEWABLE_DATA_DIR: "data/renewable"
      RENEWABLE_N_JOBS: "1"
      OMP_NUM_THREADS: "1"
      MKL_NUM_THREADS: "1"
      OPENBLAS_NUM_THREADS: "1"
      NUMBA_NUM_THREADS: "1"
      VECLIB_MAXIMUM_THREADS: "1"
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Check EIA API key
        run: |
          if [ -z "$EIA_API_KEY" ]; then
            echo "EIA_API_KEY is not set. Add it to repo secrets." >&2
            exit 1
          fi

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          # Install from pyproject.toml for single source of truth
          # Use -e for editable install (allows imports to work correctly)
          pip install -e .

      - name: Run hourly pipeline
        id: pipeline
        run: |
          python -m src.renewable.jobs.run_hourly

      - name: Quality gate check
        if: steps.pipeline.outputs.status != 'skipped'
        run: |
          python -c "
          import json, sys
          from pathlib import Path
          log_path = Path('data/renewable/run_log.json')
          if not log_path.exists():
              print('No run_log.json found')
              sys.exit(1)
          log = json.loads(log_path.read_text())
          val = log.get('validation', {})
          if not val.get('ok'):
              print(f'VALIDATION FAILED: {val.get(\"message\")}')
              print(f'Details: {val.get(\"details\")}')
              sys.exit(1)
          gates = log.get('quality_gates', {})
          if not gates.get('rowdrop', {}).get('ok', True):
              print(f'ROWDROP GATE FAILED: {gates.get(\"rowdrop\")}')
              sys.exit(1)
          if not gates.get('neg_forecast', {}).get('ok', True):
              print(f'NEG_FORECAST GATE FAILED: {gates.get(\"neg_forecast\")}')
              sys.exit(1)
          print('QUALITY GATES PASSED')
          "

      - name: Skip notification
        if: steps.pipeline.outputs.status == 'skipped'
        run: |
          echo "### Pipeline skipped - no new EIA data" >> "$GITHUB_STEP_SUMMARY"
          if [ -f data/renewable/skip_log.json ]; then
            python -c "
          import json
          from pathlib import Path
          data = json.loads(Path('data/renewable/skip_log.json').read_text())
          freshness = data.get('freshness_check', {})
          print(f'- Checked at: {freshness.get(\"checked_at_utc\")}')
          print(f'- Summary: {freshness.get(\"summary\")}')
          " >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Summarize run
        if: always() && steps.pipeline.outputs.status != 'skipped'
        run: |
          if [ -f data/renewable/run_log.json ]; then
          python - <<'PY' | tee -a "$GITHUB_STEP_SUMMARY"
          import json
          from pathlib import Path

          data = json.loads(Path("data/renewable/run_log.json").read_text())
          validation = data.get("validation", {})
          details = validation.get("details", {})
          pipeline = data.get("pipeline_results", {})
          interp = pipeline.get("interpretability", {})

          lines = [
              "### Renewable hourly run",
              f"- run_at_utc: {data.get('run_at_utc')}",
              f"- validation_ok: {validation.get('ok')}",
              f"- message: {validation.get('message')}",
              f"- max_ds: {details.get('max_ds')}",
              f"- lag_hours: {details.get('lag_hours')}",
              f"- best_model: {pipeline.get('best_model')}",
              f"- best_rmse: {pipeline.get('best_rmse', 0):.1f}",
              "",
              "#### Interpretability",
              f"- series_count: {interp.get('series_count', 0)}",
              f"- output_dir: {interp.get('output_dir', 'N/A')}",
          ]
          print("\n".join(lines))
          PY
          else
          echo "No run_log.json found." >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Commit updated artifacts
        if: steps.pipeline.outputs.status != 'skipped'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add data/renewable/generation.parquet \
            data/renewable/weather.parquet \
            data/renewable/forecasts.parquet \
            data/renewable/run_log.json
          # Add interpretability artifacts if they exist
          if [ -d data/renewable/interpretability ]; then
            git add data/renewable/interpretability/
          fi
          git commit -m "renewable: hourly data update (UTC)" || echo "No changes to commit"
          git push
