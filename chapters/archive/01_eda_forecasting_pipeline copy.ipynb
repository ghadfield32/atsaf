{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d10a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 14:24:44,447 - __main__ - INFO - MLflow is available for experiment tracking\n",
      "2026-01-08 14:24:44,453 - __main__ - INFO - Fetcher initialized (API key length: 40)\n",
      "2026-01-08 14:24:44,454 - __main__ - INFO - Starting full pipeline: 2024-12-01 to 2024-12-31\n",
      "2026-01-08 14:24:44,454 - __main__ - INFO - Pulling raw data from EIA API\n",
      "2026-01-08 14:24:44,455 - __main__ - INFO - API request: offset=0, length=5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Fetcher initialized (API key length: 40)\n",
      "\n",
      "============================================================\n",
      "FULL PIPELINE: Pull -> Prepare -> Validate -> Stats\n",
      "============================================================\n",
      "\n",
      "Step 2: Pulling data from EIA API...\n",
      "  Date range: 2024-12-01 to 2024-12-31\n",
      "  Respondent: US48\n",
      "  Fuel type: NG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 14:24:46,259 - __main__ - INFO - API request: offset=5000, length=5000\n",
      "2026-01-08 14:24:47,802 - __main__ - INFO - Data pull complete: 721 rows in 2 API requests\n",
      "2026-01-08 14:24:47,803 - __main__ - INFO - Raw data shape: (721, 7)\n",
      "2026-01-08 14:24:47,806 - __main__ - INFO - Preparing data\n",
      "2026-01-08 14:24:47,809 - __main__ - INFO - Timezone policy: UTC normalization applied\n",
      "2026-01-08 14:24:47,813 - __main__ - INFO - Data preparation complete: 721 rows\n",
      "2026-01-08 14:24:47,814 - __main__ - INFO - Validating data\n",
      "2026-01-08 14:24:47,815 - __main__ - INFO - Data validation passed\n",
      "2026-01-08 14:24:47,815 - __main__ - INFO - Computing statistics\n",
      "2026-01-08 14:24:47,816 - __main__ - INFO - Full pipeline completed successfully\n",
      "2026-01-08 14:24:47,822 - __main__ - INFO - Prepared 721 records for forecasting with unique_id=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sending requests...\n",
      "  [OK] Retrieved 721 total rows across 2 request(s)\n",
      "  Columns: period, respondent, respondent-name, fueltype, type-name, value, value-units\n",
      "\n",
      "Step 3: Inspecting data structure...\n",
      "  Shape: 721 rows x 7 columns\n",
      "\n",
      "  Column info:\n",
      "    - period: object (721 non-null)\n",
      "    - respondent: object (721 non-null)\n",
      "    - respondent-name: object (721 non-null)\n",
      "    - fueltype: object (721 non-null)\n",
      "    - type-name: object (721 non-null)\n",
      "    - value: object (721 non-null)\n",
      "    - value-units: object (721 non-null)\n",
      "\n",
      "  First 3 rows:\n",
      "    Row 0: {'period': '2024-12-01T00', 'respondent': 'US48', 'respondent-name': 'United States Lower 48', 'fueltype': 'NG', 'type-name': 'Natural Gas', 'value': '215831', 'value-units': 'megawatthours'}\n",
      "    Row 1: {'period': '2024-12-01T01', 'respondent': 'US48', 'respondent-name': 'United States Lower 48', 'fueltype': 'NG', 'type-name': 'Natural Gas', 'value': '217580', 'value-units': 'megawatthours'}\n",
      "    Row 2: {'period': '2024-12-01T02', 'respondent': 'US48', 'respondent-name': 'United States Lower 48', 'fueltype': 'NG', 'type-name': 'Natural Gas', 'value': '218150', 'value-units': 'megawatthours'}\n",
      "\n",
      "Step 4: Preparing data...\n",
      "  - Parsing period field...\n",
      "  - Applying timezone policy: UTC\n",
      "  - Extracting date...\n",
      "  - Converting value to numeric...\n",
      "  - Sorting by datetime...\n",
      "  [OK] Data prepared: 721 rows, 5 columns\n",
      "\n",
      "Step 5: Validating data...\n",
      "  [OK] Data is not empty: 721 rows\n",
      "  [OK] Value column is numeric\n",
      "  [OK] No missing values in 'value' column\n",
      "  [OK] Dates are in chronological order\n",
      "  [OK] Value range is reasonable\n",
      "\n",
      "  Validation: 5/5 checks passed\n",
      "\n",
      "Step 6: Calculating statistics...\n",
      "  Date range: 2024-12-01 to 2024-12-31\n",
      "  Record count: 721\n",
      "  Value range: 121634 to 251596 MWh\n",
      "  Value mean: 185416 MWh\n",
      "  Value std: 23879 MWh\n",
      "  Missing values: 0\n",
      "\n",
      "============================================================\n",
      "PIPELINE COMPLETE\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RESULTS\n",
      "============================================================\n",
      "\n",
      "DataFrame shape: (721, 5)\n",
      "\n",
      "First 5 rows:\n",
      "         date                    period   value respondent fueltype\n",
      "0  2024-12-01 2024-12-01 00:00:00+00:00  215831       US48       NG\n",
      "1  2024-12-01 2024-12-01 01:00:00+00:00  217580       US48       NG\n",
      "2  2024-12-01 2024-12-01 02:00:00+00:00  218150       US48       NG\n",
      "3  2024-12-01 2024-12-01 03:00:00+00:00  215705       US48       NG\n",
      "4  2024-12-01 2024-12-01 04:00:00+00:00  211670       US48       NG\n",
      "\n",
      "Last 5 rows:\n",
      "           date                    period   value respondent fueltype\n",
      "716  2024-12-30 2024-12-30 20:00:00+00:00  138371       US48       NG\n",
      "717  2024-12-30 2024-12-30 21:00:00+00:00  143695       US48       NG\n",
      "718  2024-12-30 2024-12-30 22:00:00+00:00  154437       US48       NG\n",
      "719  2024-12-30 2024-12-30 23:00:00+00:00  165941       US48       NG\n",
      "720  2024-12-31 2024-12-31 00:00:00+00:00  176563       US48       NG\n",
      "\n",
      "[OK] Data successfully loaded from .env file!\n",
      "[OK] Ready for time series analysis and forecasting\n",
      "\n",
      "============================================================\n",
      "FORECASTING WORKFLOW\n",
      "============================================================\n",
      "\n",
      "Data reformatted for forecasting:\n",
      "  Columns: ['unique_id', 'ds', 'y']\n",
      "  Shape: (721, 3)\n",
      "\n",
      "Train/Test Split:\n",
      "  Training set: 649 records\n",
      "  Testing set: 72 records\n",
      "  Split point: 2024-12-28 00:00:00+00:00\n",
      "\n",
      "Training 6 models...\n",
      "  Models: AutoARIMA, SeasonalNaive, DynamicOptimizedTheta, HoltWinters, MSTL, MSTL\n",
      "  Horizon: 72 hours\n",
      "  Confidence level: 95%\n",
      "  [OK] Forecast generated: 72 predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 14:26:13,370 - __main__ - INFO - Evaluation merge: 72 forecast rows, 72 test rows, 72 merged rows\n",
      "2026-01-08 14:26:13,381 - __main__ - INFO - Evaluation complete: 72 valid rows, 6 models evaluated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics (on 72 valid rows out of 72 total):\n",
      "Model                MAPE     RMSE     MASE     Coverage   Valid   \n",
      "--------------------------------------------------------------\n",
      "MSTL_ARIMA           0.0800  13805    N/A      87.5%      72      \n",
      "SeasonalNaive        0.1460  22754    N/A      100.0%     72      \n",
      "AutoARIMA            0.1558  25216    N/A      84.7%      72      \n",
      "DynamicOptimizedTheta 0.1592  25529    N/A      86.1%      72      \n",
      "HoltWinters          0.1612  25690    N/A      47.2%      72      \n",
      "MSTL_HoltWinters     0.2408  37913    N/A      100.0%     72      \n",
      "\n",
      "============================================================\n",
      "VISUALIZATION\n",
      "============================================================\n",
      "\n",
      "Generating forecast visualization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "mode": "lines",
         "name": "Actual",
         "type": "scatter",
         "x": [
          "2024-12-28T01:00:00.000000000",
          "2024-12-28T02:00:00.000000000",
          "2024-12-28T03:00:00.000000000",
          "2024-12-28T04:00:00.000000000",
          "2024-12-28T05:00:00.000000000",
          "2024-12-28T06:00:00.000000000",
          "2024-12-28T07:00:00.000000000",
          "2024-12-28T08:00:00.000000000",
          "2024-12-28T09:00:00.000000000",
          "2024-12-28T10:00:00.000000000",
          "2024-12-28T11:00:00.000000000",
          "2024-12-28T12:00:00.000000000",
          "2024-12-28T13:00:00.000000000",
          "2024-12-28T14:00:00.000000000",
          "2024-12-28T15:00:00.000000000",
          "2024-12-28T16:00:00.000000000",
          "2024-12-28T17:00:00.000000000",
          "2024-12-28T18:00:00.000000000",
          "2024-12-28T19:00:00.000000000",
          "2024-12-28T20:00:00.000000000",
          "2024-12-28T21:00:00.000000000",
          "2024-12-28T22:00:00.000000000",
          "2024-12-28T23:00:00.000000000",
          "2024-12-29T00:00:00.000000000",
          "2024-12-29T01:00:00.000000000",
          "2024-12-29T02:00:00.000000000",
          "2024-12-29T03:00:00.000000000",
          "2024-12-29T04:00:00.000000000",
          "2024-12-29T05:00:00.000000000",
          "2024-12-29T06:00:00.000000000",
          "2024-12-29T07:00:00.000000000",
          "2024-12-29T08:00:00.000000000",
          "2024-12-29T09:00:00.000000000",
          "2024-12-29T10:00:00.000000000",
          "2024-12-29T11:00:00.000000000",
          "2024-12-29T12:00:00.000000000",
          "2024-12-29T13:00:00.000000000",
          "2024-12-29T14:00:00.000000000",
          "2024-12-29T15:00:00.000000000",
          "2024-12-29T16:00:00.000000000",
          "2024-12-29T17:00:00.000000000",
          "2024-12-29T18:00:00.000000000",
          "2024-12-29T19:00:00.000000000",
          "2024-12-29T20:00:00.000000000",
          "2024-12-29T21:00:00.000000000",
          "2024-12-29T22:00:00.000000000",
          "2024-12-29T23:00:00.000000000",
          "2024-12-30T00:00:00.000000000",
          "2024-12-30T01:00:00.000000000",
          "2024-12-30T02:00:00.000000000",
          "2024-12-30T03:00:00.000000000",
          "2024-12-30T04:00:00.000000000",
          "2024-12-30T05:00:00.000000000",
          "2024-12-30T06:00:00.000000000",
          "2024-12-30T07:00:00.000000000",
          "2024-12-30T08:00:00.000000000",
          "2024-12-30T09:00:00.000000000",
          "2024-12-30T10:00:00.000000000",
          "2024-12-30T11:00:00.000000000",
          "2024-12-30T12:00:00.000000000",
          "2024-12-30T13:00:00.000000000",
          "2024-12-30T14:00:00.000000000",
          "2024-12-30T15:00:00.000000000",
          "2024-12-30T16:00:00.000000000",
          "2024-12-30T17:00:00.000000000",
          "2024-12-30T18:00:00.000000000",
          "2024-12-30T19:00:00.000000000",
          "2024-12-30T20:00:00.000000000",
          "2024-12-30T21:00:00.000000000",
          "2024-12-30T22:00:00.000000000",
          "2024-12-30T23:00:00.000000000",
          "2024-12-31T00:00:00.000000000"
         ],
         "y": {
          "bdata": "Ju8CAMjXAgDjvgIALqUCAPqFAgAGSAIA4CoCANsbAgB0EgIAgxYCAMQbAgCqLAIA0D4CAJxTAgBqXQIASV8CALRjAgC/YgIAgmoCAEBoAgBDdAIAT4gCAFCrAgCTzgIAI8QCAFqyAgB7pAIApI0CAHVtAgA+WAIAazkCALkkAgBNFwIAsA4CAL4OAgC0FgIAsiYCAHU0AgDgQAIA5EUCAIdJAgArSQIAcEcCAItJAgBiVwIADm8CALmZAgA8tgIAUq4CAIeZAgBKegIA3VACAKwvAgD/AQIArOwBAHPiAQAi2wEAnesBAGYIAgDRMQIA20oCAJVQAgCkRwIAKDQCALMiAgCiFgIAlRMCAIMcAgBPMQIARVsCADWIAgCzsQIA",
          "dtype": "i4"
         }
        },
        {
         "line": {
          "color": "red",
          "dash": "dash",
          "width": 2
         },
         "mode": "lines",
         "name": "MSTL_ARIMA (Best)",
         "type": "scatter",
         "x": [
          "2024-12-28T01:00:00.000000000",
          "2024-12-28T02:00:00.000000000",
          "2024-12-28T03:00:00.000000000",
          "2024-12-28T04:00:00.000000000",
          "2024-12-28T05:00:00.000000000",
          "2024-12-28T06:00:00.000000000",
          "2024-12-28T07:00:00.000000000",
          "2024-12-28T08:00:00.000000000",
          "2024-12-28T09:00:00.000000000",
          "2024-12-28T10:00:00.000000000",
          "2024-12-28T11:00:00.000000000",
          "2024-12-28T12:00:00.000000000",
          "2024-12-28T13:00:00.000000000",
          "2024-12-28T14:00:00.000000000",
          "2024-12-28T15:00:00.000000000",
          "2024-12-28T16:00:00.000000000",
          "2024-12-28T17:00:00.000000000",
          "2024-12-28T18:00:00.000000000",
          "2024-12-28T19:00:00.000000000",
          "2024-12-28T20:00:00.000000000",
          "2024-12-28T21:00:00.000000000",
          "2024-12-28T22:00:00.000000000",
          "2024-12-28T23:00:00.000000000",
          "2024-12-29T00:00:00.000000000",
          "2024-12-29T01:00:00.000000000",
          "2024-12-29T02:00:00.000000000",
          "2024-12-29T03:00:00.000000000",
          "2024-12-29T04:00:00.000000000",
          "2024-12-29T05:00:00.000000000",
          "2024-12-29T06:00:00.000000000",
          "2024-12-29T07:00:00.000000000",
          "2024-12-29T08:00:00.000000000",
          "2024-12-29T09:00:00.000000000",
          "2024-12-29T10:00:00.000000000",
          "2024-12-29T11:00:00.000000000",
          "2024-12-29T12:00:00.000000000",
          "2024-12-29T13:00:00.000000000",
          "2024-12-29T14:00:00.000000000",
          "2024-12-29T15:00:00.000000000",
          "2024-12-29T16:00:00.000000000",
          "2024-12-29T17:00:00.000000000",
          "2024-12-29T18:00:00.000000000",
          "2024-12-29T19:00:00.000000000",
          "2024-12-29T20:00:00.000000000",
          "2024-12-29T21:00:00.000000000",
          "2024-12-29T22:00:00.000000000",
          "2024-12-29T23:00:00.000000000",
          "2024-12-30T00:00:00.000000000",
          "2024-12-30T01:00:00.000000000",
          "2024-12-30T02:00:00.000000000",
          "2024-12-30T03:00:00.000000000",
          "2024-12-30T04:00:00.000000000",
          "2024-12-30T05:00:00.000000000",
          "2024-12-30T06:00:00.000000000",
          "2024-12-30T07:00:00.000000000",
          "2024-12-30T08:00:00.000000000",
          "2024-12-30T09:00:00.000000000",
          "2024-12-30T10:00:00.000000000",
          "2024-12-30T11:00:00.000000000",
          "2024-12-30T12:00:00.000000000",
          "2024-12-30T13:00:00.000000000",
          "2024-12-30T14:00:00.000000000",
          "2024-12-30T15:00:00.000000000",
          "2024-12-30T16:00:00.000000000",
          "2024-12-30T17:00:00.000000000",
          "2024-12-30T18:00:00.000000000",
          "2024-12-30T19:00:00.000000000",
          "2024-12-30T20:00:00.000000000",
          "2024-12-30T21:00:00.000000000",
          "2024-12-30T22:00:00.000000000",
          "2024-12-30T23:00:00.000000000",
          "2024-12-31T00:00:00.000000000"
         ],
         "y": {
          "bdata": "JSs8SDldOUjNHjZIa6YxSI0nLkhACCZIT3AhSFWBH0h41x5I4lcfSCPWIEjTGSNIuvYmSGxrJ0gjLCNIWpwdSD32GUghjhdIJ8YWSOwRFkgqzhlIDTIiSC4BLEggnCxIMeIqSPKXKEgGkSZIvygjSEryH0jCMxhIBDUTSAk6EUhi/g5IPZoNSN2rDEgyFA1I0lsQSFGdEEgAAw5IJVoGSNy/AUgzef1Hrfr8Ry/D/0exFgRI8OANSAROGEj2fx5IpNAdSGPPHEgJuxlIGMIUSH+PEkiW+wtI4lkJSBP3CEjgSglI/3EMSEk+EkiXOBtI8vwhSAqQIkgumB9IYwgbSFfDFkhPkBVIMfwVSEFCF0jjyBtIX/ckSI4gLkgcIzRI",
          "dtype": "f4"
         }
        },
        {
         "fill": "toself",
         "fillcolor": "rgba(255, 0, 0, 0.2)",
         "line": {
          "color": "rgba(255, 0, 0, 0)"
         },
         "name": "95% Confidence Interval",
         "type": "scatter",
         "x": [
          "2024-12-28T01:00:00+00:00",
          "2024-12-28T02:00:00+00:00",
          "2024-12-28T03:00:00+00:00",
          "2024-12-28T04:00:00+00:00",
          "2024-12-28T05:00:00+00:00",
          "2024-12-28T06:00:00+00:00",
          "2024-12-28T07:00:00+00:00",
          "2024-12-28T08:00:00+00:00",
          "2024-12-28T09:00:00+00:00",
          "2024-12-28T10:00:00+00:00",
          "2024-12-28T11:00:00+00:00",
          "2024-12-28T12:00:00+00:00",
          "2024-12-28T13:00:00+00:00",
          "2024-12-28T14:00:00+00:00",
          "2024-12-28T15:00:00+00:00",
          "2024-12-28T16:00:00+00:00",
          "2024-12-28T17:00:00+00:00",
          "2024-12-28T18:00:00+00:00",
          "2024-12-28T19:00:00+00:00",
          "2024-12-28T20:00:00+00:00",
          "2024-12-28T21:00:00+00:00",
          "2024-12-28T22:00:00+00:00",
          "2024-12-28T23:00:00+00:00",
          "2024-12-29T00:00:00+00:00",
          "2024-12-29T01:00:00+00:00",
          "2024-12-29T02:00:00+00:00",
          "2024-12-29T03:00:00+00:00",
          "2024-12-29T04:00:00+00:00",
          "2024-12-29T05:00:00+00:00",
          "2024-12-29T06:00:00+00:00",
          "2024-12-29T07:00:00+00:00",
          "2024-12-29T08:00:00+00:00",
          "2024-12-29T09:00:00+00:00",
          "2024-12-29T10:00:00+00:00",
          "2024-12-29T11:00:00+00:00",
          "2024-12-29T12:00:00+00:00",
          "2024-12-29T13:00:00+00:00",
          "2024-12-29T14:00:00+00:00",
          "2024-12-29T15:00:00+00:00",
          "2024-12-29T16:00:00+00:00",
          "2024-12-29T17:00:00+00:00",
          "2024-12-29T18:00:00+00:00",
          "2024-12-29T19:00:00+00:00",
          "2024-12-29T20:00:00+00:00",
          "2024-12-29T21:00:00+00:00",
          "2024-12-29T22:00:00+00:00",
          "2024-12-29T23:00:00+00:00",
          "2024-12-30T00:00:00+00:00",
          "2024-12-30T01:00:00+00:00",
          "2024-12-30T02:00:00+00:00",
          "2024-12-30T03:00:00+00:00",
          "2024-12-30T04:00:00+00:00",
          "2024-12-30T05:00:00+00:00",
          "2024-12-30T06:00:00+00:00",
          "2024-12-30T07:00:00+00:00",
          "2024-12-30T08:00:00+00:00",
          "2024-12-30T09:00:00+00:00",
          "2024-12-30T10:00:00+00:00",
          "2024-12-30T11:00:00+00:00",
          "2024-12-30T12:00:00+00:00",
          "2024-12-30T13:00:00+00:00",
          "2024-12-30T14:00:00+00:00",
          "2024-12-30T15:00:00+00:00",
          "2024-12-30T16:00:00+00:00",
          "2024-12-30T17:00:00+00:00",
          "2024-12-30T18:00:00+00:00",
          "2024-12-30T19:00:00+00:00",
          "2024-12-30T20:00:00+00:00",
          "2024-12-30T21:00:00+00:00",
          "2024-12-30T22:00:00+00:00",
          "2024-12-30T23:00:00+00:00",
          "2024-12-31T00:00:00+00:00",
          "2024-12-31T00:00:00+00:00",
          "2024-12-30T23:00:00+00:00",
          "2024-12-30T22:00:00+00:00",
          "2024-12-30T21:00:00+00:00",
          "2024-12-30T20:00:00+00:00",
          "2024-12-30T19:00:00+00:00",
          "2024-12-30T18:00:00+00:00",
          "2024-12-30T17:00:00+00:00",
          "2024-12-30T16:00:00+00:00",
          "2024-12-30T15:00:00+00:00",
          "2024-12-30T14:00:00+00:00",
          "2024-12-30T13:00:00+00:00",
          "2024-12-30T12:00:00+00:00",
          "2024-12-30T11:00:00+00:00",
          "2024-12-30T10:00:00+00:00",
          "2024-12-30T09:00:00+00:00",
          "2024-12-30T08:00:00+00:00",
          "2024-12-30T07:00:00+00:00",
          "2024-12-30T06:00:00+00:00",
          "2024-12-30T05:00:00+00:00",
          "2024-12-30T04:00:00+00:00",
          "2024-12-30T03:00:00+00:00",
          "2024-12-30T02:00:00+00:00",
          "2024-12-30T01:00:00+00:00",
          "2024-12-30T00:00:00+00:00",
          "2024-12-29T23:00:00+00:00",
          "2024-12-29T22:00:00+00:00",
          "2024-12-29T21:00:00+00:00",
          "2024-12-29T20:00:00+00:00",
          "2024-12-29T19:00:00+00:00",
          "2024-12-29T18:00:00+00:00",
          "2024-12-29T17:00:00+00:00",
          "2024-12-29T16:00:00+00:00",
          "2024-12-29T15:00:00+00:00",
          "2024-12-29T14:00:00+00:00",
          "2024-12-29T13:00:00+00:00",
          "2024-12-29T12:00:00+00:00",
          "2024-12-29T11:00:00+00:00",
          "2024-12-29T10:00:00+00:00",
          "2024-12-29T09:00:00+00:00",
          "2024-12-29T08:00:00+00:00",
          "2024-12-29T07:00:00+00:00",
          "2024-12-29T06:00:00+00:00",
          "2024-12-29T05:00:00+00:00",
          "2024-12-29T04:00:00+00:00",
          "2024-12-29T03:00:00+00:00",
          "2024-12-29T02:00:00+00:00",
          "2024-12-29T01:00:00+00:00",
          "2024-12-29T00:00:00+00:00",
          "2024-12-28T23:00:00+00:00",
          "2024-12-28T22:00:00+00:00",
          "2024-12-28T21:00:00+00:00",
          "2024-12-28T20:00:00+00:00",
          "2024-12-28T19:00:00+00:00",
          "2024-12-28T18:00:00+00:00",
          "2024-12-28T17:00:00+00:00",
          "2024-12-28T16:00:00+00:00",
          "2024-12-28T15:00:00+00:00",
          "2024-12-28T14:00:00+00:00",
          "2024-12-28T13:00:00+00:00",
          "2024-12-28T12:00:00+00:00",
          "2024-12-28T11:00:00+00:00",
          "2024-12-28T10:00:00+00:00",
          "2024-12-28T09:00:00+00:00",
          "2024-12-28T08:00:00+00:00",
          "2024-12-28T07:00:00+00:00",
          "2024-12-28T06:00:00+00:00",
          "2024-12-28T05:00:00+00:00",
          "2024-12-28T04:00:00+00:00",
          "2024-12-28T03:00:00+00:00",
          "2024-12-28T02:00:00+00:00",
          "2024-12-28T01:00:00+00:00"
         ],
         "y": [
          196527.5,
          196367.84375,
          195326.328125,
          192706.484375,
          190721.234375,
          183746.703125,
          180135.328125,
          179086.6875,
          179180.859375,
          180373.578125,
          182485.1875,
          185333.65625,
          189759.609375,
          190668.28125,
          186723.4375,
          181417.9375,
          178046.171875,
          175939.359375,
          175479.453125,
          175095.484375,
          179244.0625,
          188158.203125,
          198514.5,
          199445.984375,
          197980.734375,
          195938.5,
          194157.390625,
          190963.21875,
          187960.96875,
          180318.6875,
          175484.828125,
          173738.203125,
          171726.671875,
          170577.234375,
          169893.140625,
          170579.84375,
          174202.390625,
          174728.3125,
          172322.046875,
          164737.421875,
          160278.453125,
          157447.359375,
          157443.96875,
          159118.3125,
          163672.046875,
          173942,
          184859.546875,
          191444.171875,
          190980.203125,
          190188.09375,
          187268.28125,
          182409.65625,
          180389.328125,
          173883.234375,
          171415.09375,
          171246,
          171804.625,
          175255.96875,
          181413.421875,
          190826.375,
          197973.125,
          198778.21875,
          195953.21875,
          191495.90625,
          187335.40625,
          186318.34375,
          186958.921875,
          188471.578125,
          193312.59375,
          202920.375,
          212505.109375,
          218862.6875,
          150058.1875,
          144107.34375,
          134930.609375,
          125734.515625,
          121306.453125,
          120210.6171875,
          119988.1171875,
          121427.3203125,
          126011.1953125,
          130896.203125,
          134150.09375,
          133778.453125,
          127066.34375,
          118092.859375,
          112376.0078125,
          109370.3828125,
          109258.6015625,
          109879.9609375,
          112801.4453125,
          119766.6484375,
          122247.09375,
          127571.984375,
          130959.015625,
          132224.90625,
          133163.53125,
          127060.5703125,
          116625.4921875,
          106845.484375,
          102782.421875,
          101606.7421875,
          102109.4296875,
          105448.40625,
          110415.7421875,
          118517.96875,
          121442.2109375,
          121444.15625,
          118349.7109375,
          118201.765625,
          119424.6640625,
          121124.40625,
          123686.0859375,
          125995.296875,
          131391.375,
          139609.359375,
          143186.75,
          146970.78125,
          149341.078125,
          151988.8125,
          154059.03125,
          153750.921875,
          144018.203125,
          135749.234375,
          132247.890625,
          133305.765625,
          134445.671875,
          137267.71875,
          141368.875,
          147453.65625,
          152207.09375,
          152182.203125,
          148696.9375,
          146907.90625,
          145961.46875,
          146126.875,
          147579.96875,
          150491.140625,
          156287.296875,
          165947.1875,
          171120.875,
          177656.09375,
          183257.9375,
          188841.65625
         ]
        }
       ],
       "layout": {
        "height": 400,
        "hovermode": "x unified",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "EIA Electricity Generation: Forecast vs Actual"
        },
        "xaxis": {
         "title": {
          "text": "Date"
         }
        },
        "yaxis": {
         "title": {
          "text": "Generation (MWh)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] Forecast plot displayed\n",
      "\n",
      "[OK] Forecasting workflow complete!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "EIA Data Fetcher - Step by Step\n",
    "=================================\n",
    "\n",
    "A simplified module for pulling EIA electricity generation data\n",
    "following the same step-by-step approach as the R script.\n",
    "\n",
    "This module makes it easy to understand each step and test along the way.\n",
    "\n",
    "Usage:\n",
    "    from eia_data_simple import EIADataFetcher\n",
    "    import os\n",
    "    \n",
    "    # Step 1: Initialize\n",
    "    api_key = os.getenv(\"EIA_API_KEY\")\n",
    "    fetcher = EIADataFetcher(api_key)\n",
    "    \n",
    "    # Step 2: Pull raw data\n",
    "    df_raw = fetcher.pull_data(\n",
    "        start_date=\"2023-01-01\",\n",
    "        end_date=\"2024-12-31\"\n",
    "    )\n",
    "    \n",
    "    # Step 3: Inspect data\n",
    "    print(f\"Rows: {len(df_raw)}\")\n",
    "    print(df_raw.head())\n",
    "    \n",
    "    # Step 4: Prepare (convert types, sort, etc.)\n",
    "    df_prepared = fetcher.prepare_data(df_raw)\n",
    "    \n",
    "    # Step 5: Validate\n",
    "    is_valid = fetcher.validate_data(df_prepared)\n",
    "    \n",
    "    # Step 6: Get statistics\n",
    "    stats = fetcher.get_stats(df_prepared)\n",
    "    print(stats)\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Optional: pydantic-settings for type-safe config\n",
    "try:\n",
    "    from pydantic_settings import BaseSettings\n",
    "    PYDANTIC_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYDANTIC_AVAILABLE = False\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Optional: MLflow for experiment tracking\n",
    "try:\n",
    "    import mlflow\n",
    "    from mlflow.models import infer_signature\n",
    "    MLFLOW_AVAILABLE = True\n",
    "    logger.info(\"MLflow is available for experiment tracking\")\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    logger.warning(\"MLflow not available - experiment tracking disabled\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION CLASSES\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"\n",
    "    Configuration for backtesting experiments.\n",
    "\n",
    "    This defines the \"contract\" for reproducible experiments:\n",
    "    - What data range to use\n",
    "    - How to split for cross-validation\n",
    "    - Which models and metrics to evaluate\n",
    "\n",
    "    Example:\n",
    "        >>> config = ExperimentConfig(\n",
    "        ...     name=\"baseline_experiment\",\n",
    "        ...     horizon=24,\n",
    "        ...     n_windows=5,\n",
    "        ...     step_size=168,  # Weekly steps\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    name: str = \"default_experiment\"\n",
    "    horizon: int = 24              # Forecast horizon in hours\n",
    "    n_windows: int = 5             # Number of CV windows\n",
    "    step_size: int = 168           # Hours between windows (168 = 1 week)\n",
    "    confidence_level: int = 95     # Prediction interval level\n",
    "    models: List[str] = field(default_factory=lambda: [\n",
    "        \"SeasonalNaive\", \"AutoARIMA\", \"MSTL\"\n",
    "    ])\n",
    "    metrics: List[str] = field(default_factory=lambda: [\n",
    "        \"rmse\", \"mape\", \"mase\", \"coverage\"\n",
    "    ])\n",
    "\n",
    "\n",
    "# Pydantic-settings config (if available)\n",
    "if PYDANTIC_AVAILABLE:\n",
    "    class Settings(BaseSettings):\n",
    "        \"\"\"\n",
    "        Type-safe configuration using pydantic-settings.\n",
    "\n",
    "        Automatically reads from environment variables or .env file.\n",
    "        Validates types and provides defaults.\n",
    "\n",
    "        Example:\n",
    "            >>> settings = Settings()\n",
    "            >>> print(settings.eia_api_key[:8])\n",
    "        \"\"\"\n",
    "        eia_api_key: str\n",
    "        respondent: str = \"US48\"\n",
    "        fueltype: str = \"NG\"\n",
    "        start_date: str = \"2024-01-01\"\n",
    "        end_date: str = \"2024-12-31\"\n",
    "\n",
    "        class Config:\n",
    "            env_file = \".env\"\n",
    "            env_file_encoding = \"utf-8\"\n",
    "\n",
    "\n",
    "class EIADataFetcher:\n",
    "    \"\"\"\n",
    "    Step-by-step EIA data fetcher matching R script workflow.\n",
    "    \n",
    "    Each method represents a step in the data pipeline:\n",
    "    1. pull_data() - Fetch from API\n",
    "    2. inspect_data() - View structure\n",
    "    3. prepare_data() - Clean and convert\n",
    "    4. validate_data() - Check quality\n",
    "    5. get_stats() - Calculate summary stats\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the fetcher with API credentials.\n",
    "        \n",
    "        Args:\n",
    "            api_key: EIA API key from https://www.eia.gov/opendata/\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.api_url = \"https://api.eia.gov/v2/electricity/rto/fuel-type-data/data/\"\n",
    "        logger.info(f\"Fetcher initialized (API key length: {len(api_key)})\")\n",
    "        print(f\"Step 1: Fetcher initialized (API key length: {len(api_key)})\")\n",
    "    \n",
    "    def pull_data(\n",
    "        self,\n",
    "        start_date: str = \"2023-01-01\",\n",
    "        end_date: str = \"2024-12-31\",\n",
    "        respondent: str = \"US48\",\n",
    "        fueltype: str = \"NG\",\n",
    "        length: int = 5000\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        STEP 2: Pull raw data from EIA API with pagination.\n",
    "        \n",
    "        Features:\n",
    "        - Handles >5000 row datasets with pagination loop\n",
    "        - Stable sort order (period ascending) for reproducibility\n",
    "        - Logs pagination details for transparency\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start date (YYYY-MM-DD)\n",
    "            end_date: End date (YYYY-MM-DD)\n",
    "            respondent: Region code (default: US48 = Lower 48 states)\n",
    "            fueltype: Fuel type code (default: NG = Natural Gas)\n",
    "            length: Records per request (default: 5000, max allowed)\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with raw API response\n",
    "        \n",
    "        Example:\n",
    "            >>> df_raw = fetcher.pull_data()\n",
    "            >>> print(f\"Retrieved {len(df_raw)} rows\")\n",
    "        \"\"\"\n",
    "        print(f\"\\nStep 2: Pulling data from EIA API...\")\n",
    "        print(f\"  Date range: {start_date} to {end_date}\")\n",
    "        print(f\"  Respondent: {respondent}\")\n",
    "        print(f\"  Fuel type: {fueltype}\")\n",
    "        \n",
    "        all_records = []\n",
    "        offset = 0\n",
    "        request_count = 0\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # Build API parameters with pagination and STABLE SORT\n",
    "                # Using sort params ensures pages don't shuffle during pagination\n",
    "                params = {\n",
    "                    \"api_key\": self.api_key,\n",
    "                    \"data[]\": \"value\",\n",
    "                    \"facets[respondent][]\": respondent,\n",
    "                    \"facets[fueltype][]\": fueltype,\n",
    "                    \"frequency\": \"hourly\",\n",
    "                    \"start\": f\"{start_date}T00\",\n",
    "                    \"end\": f\"{end_date}T23\",\n",
    "                    \"length\": length,\n",
    "                    \"offset\": offset,\n",
    "                    # STABLE SORT: Request data in ascending order from the API\n",
    "                    # This ensures consistent ordering across paginated requests\n",
    "                    \"sort[0][column]\": \"period\",\n",
    "                    \"sort[0][direction]\": \"asc\",\n",
    "                }\n",
    "                \n",
    "                # Make API request\n",
    "                logger.info(f\"API request: offset={offset}, length={length}\")\n",
    "                response = requests.get(self.api_url, params=params)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                # Parse response\n",
    "                data = response.json()\n",
    "                records = data[\"response\"][\"data\"]\n",
    "                request_count += 1\n",
    "                \n",
    "                logger.debug(f\"Request {request_count}: received {len(records)} rows\")\n",
    "                \n",
    "                if not records:\n",
    "                    break  # No more data\n",
    "                \n",
    "                all_records.extend(records)\n",
    "                offset += length\n",
    "            \n",
    "            if not all_records:\n",
    "                raise ValueError(\"No data returned from API\")\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            # Data is already sorted ascending by period from the API (stable sort params)\n",
    "            # We still verify sort order here as a safety check\n",
    "            df = pd.DataFrame(all_records)\n",
    "            df = df.sort_values(\"period\", ascending=True).reset_index(drop=True)\n",
    "            \n",
    "            print(f\"  Sending requests...\")\n",
    "            print(f\"  [OK] Retrieved {len(df)} total rows across {request_count} request(s)\")\n",
    "            print(f\"  Columns: {', '.join(df.columns.tolist())}\")\n",
    "            \n",
    "            logger.info(f\"Data pull complete: {len(df)} rows in {request_count} API requests\")\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data pull failed: {e}\", exc_info=True)\n",
    "            print(f\"  [ERROR] {e}\")\n",
    "            raise\n",
    "    \n",
    "    def inspect_data(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        STEP 3: Inspect raw data structure.\n",
    "        \n",
    "        Displays:\n",
    "        - Data shape\n",
    "        - Column info\n",
    "        - First few rows\n",
    "        - Data types\n",
    "        \n",
    "        Example:\n",
    "            >>> fetcher.inspect_data(df_raw)\n",
    "        \"\"\"\n",
    "        print(f\"\\nStep 3: Inspecting data structure...\")\n",
    "        print(f\"  Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "        print(f\"\\n  Column info:\")\n",
    "        for col in df.columns:\n",
    "            dtype = df[col].dtype\n",
    "            non_null = df[col].notna().sum()\n",
    "            print(f\"    - {col}: {dtype} ({non_null} non-null)\")\n",
    "        \n",
    "        print(f\"\\n  First 3 rows:\")\n",
    "        for i, row in df.head(3).iterrows():\n",
    "            print(f\"    Row {i}: {dict(row)}\")\n",
    "    \n",
    "    def prepare_data(self, df: pd.DataFrame, timezone_policy: str = \"UTC\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        STEP 4: Prepare data (clean, convert, sort).\n",
    "        \n",
    "        Performs:\n",
    "        - Parse datetime from 'period' field\n",
    "        - Apply timezone policy (UTC normalization for consistency)\n",
    "        - Convert 'value' to numeric\n",
    "        - Sort by datetime\n",
    "        - Standardize column names\n",
    "        \n",
    "        Args:\n",
    "            df: Raw DataFrame from pull_data()\n",
    "            timezone_policy: \"UTC\" (recommended) - normalize all times to UTC\n",
    "        \n",
    "        Returns:\n",
    "            Cleaned and prepared DataFrame\n",
    "        \n",
    "        Example:\n",
    "            >>> df_clean = fetcher.prepare_data(df_raw, timezone_policy=\"UTC\")\n",
    "        \"\"\"\n",
    "        print(f\"\\nStep 4: Preparing data...\")\n",
    "        \n",
    "        df = df.copy()\n",
    "        \n",
    "        # Parse period to datetime (fail-loud on parse errors)\n",
    "        print(f\"  - Parsing period field...\")\n",
    "        try:\n",
    "            df[\"period\"] = pd.to_datetime(df[\"period\"], errors=\"raise\")\n",
    "        except (ValueError, TypeError) as e:\n",
    "            logger.error(f\"DateTime parsing failed: {e}\")\n",
    "            logger.error(f\"Sample period values: {df['period'].head(10).tolist()}\")\n",
    "            raise ValueError(f\"Cannot parse period field as datetime: {e}\") from e\n",
    "        \n",
    "        # Apply timezone policy (UTC normalization)\n",
    "        print(f\"  - Applying timezone policy: {timezone_policy}\")\n",
    "        if timezone_policy == \"UTC\":\n",
    "            # Assume period is in UTC if no timezone info\n",
    "            if df[\"period\"].dt.tz is None:\n",
    "                df[\"period\"] = df[\"period\"].dt.tz_localize(\"UTC\")\n",
    "            else:\n",
    "                df[\"period\"] = df[\"period\"].dt.tz_convert(\"UTC\")\n",
    "            logger.info(\"Timezone policy: UTC normalization applied\")\n",
    "        \n",
    "        # Extract date\n",
    "        print(f\"  - Extracting date...\")\n",
    "        df[\"date\"] = df[\"period\"].dt.date\n",
    "        \n",
    "        # Convert value to numeric (fail-loud on coercion)\n",
    "        print(f\"  - Converting value to numeric...\")\n",
    "        df[\"value_before_coercion\"] = df[\"value\"].copy()  # Keep original for audit\n",
    "        try:\n",
    "            df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"raise\")\n",
    "        except (ValueError, TypeError) as e:\n",
    "            # Count non-numeric values and provide detailed error\n",
    "            non_numeric_rows = df[pd.to_numeric(df[\"value\"], errors=\"coerce\").isna()]\n",
    "            logger.error(f\"Numeric conversion failed: {len(non_numeric_rows)} non-numeric rows\")\n",
    "            logger.error(f\"Sample non-numeric values: {non_numeric_rows['value'].head(5).tolist()}\")\n",
    "            raise ValueError(\n",
    "                f\"Cannot convert value column to numeric: {len(non_numeric_rows)} unparseable rows. \"\n",
    "                f\"This typically indicates upstream schema changes or data quality issues. \"\n",
    "                f\"Sample values: {non_numeric_rows['value'].head(3).tolist()}\"\n",
    "            ) from e\n",
    "        \n",
    "        # Verify no coercions occurred\n",
    "        if df[\"value\"].isna().sum() > 0:\n",
    "            coercion_count = df[\"value\"].isna().sum()\n",
    "            logger.error(f\"Coercion produced {coercion_count} NaN values during numeric conversion\")\n",
    "            raise ValueError(\n",
    "                f\"Numeric conversion coerced {coercion_count} values to NaN. \"\n",
    "                f\"Review original values: {df[df['value'].isna()]['value_before_coercion'].head(5).tolist()}\"\n",
    "            )\n",
    "        \n",
    "        # Sort by datetime\n",
    "        print(f\"  - Sorting by datetime...\")\n",
    "        df = df.sort_values(\"period\").reset_index(drop=True)\n",
    "        \n",
    "        # Standardize column names\n",
    "        df.columns = [col.lower().replace(\"-\", \"_\") for col in df.columns]\n",
    "        \n",
    "        # Remove temporary audit column if present\n",
    "        df = df.drop(columns=[\"value_before_coercion\"], errors=\"ignore\")\n",
    "        \n",
    "        # Select key columns\n",
    "        key_cols = [\"date\", \"period\", \"value\", \"respondent\", \"fueltype\"]\n",
    "        df = df[[col for col in key_cols if col in df.columns]]\n",
    "        \n",
    "        print(f\"  [OK] Data prepared: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        logger.info(f\"Data preparation complete: {df.shape[0]} rows\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def validate_time_series_integrity(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        STEP 4B: Comprehensive time series integrity validation.\n",
    "        \n",
    "        Critical checks for production:\n",
    "        - No duplicates on (unique_id, ds)\n",
    "        - Regular hourly frequency\n",
    "        - Missing hours detection\n",
    "        - DST repeated hours (freq = 0)\n",
    "        - Complete final hours for backtesting\n",
    "        \n",
    "        Args:\n",
    "            df: Prepared DataFrame from prepare_for_forecasting()\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with integrity report:\n",
    "            - duplicate_count: Number of duplicate (unique_id, ds) pairs\n",
    "            - missing_hours: Count of missing hours\n",
    "            - longest_gap_hours: Duration of longest gap\n",
    "            - dst_repeated_hours: Count of repeated hours (DST backward)\n",
    "            - gaps_detail: List of gap locations\n",
    "            - status: \"valid\" or \"invalid\"\n",
    "        \n",
    "        Example:\n",
    "            >>> df_forecast = fetcher.prepare_for_forecasting(df)\n",
    "            >>> integrity = fetcher.validate_time_series_integrity(df_forecast)\n",
    "            >>> print(integrity['status'])\n",
    "        \"\"\"\n",
    "        print(f\"\\nStep 4B: Validating time series integrity...\")\n",
    "        \n",
    "        report = {\n",
    "            \"duplicate_count\": 0,\n",
    "            \"missing_hours\": 0,\n",
    "            \"longest_gap_hours\": 0,\n",
    "            \"dst_repeated_hours\": 0,\n",
    "            \"gaps_detail\": [],\n",
    "            \"status\": \"valid\"\n",
    "        }\n",
    "        \n",
    "        df_sorted = df.sort_values([\"unique_id\", \"ds\"]).reset_index(drop=True)\n",
    "        \n",
    "        # Check 1: Duplicates on (unique_id, ds)\n",
    "        dups = df_sorted.groupby([\"unique_id\", \"ds\"]).size()\n",
    "        duplicate_rows = (dups > 1).sum()\n",
    "        report[\"duplicate_count\"] = int(duplicate_rows)\n",
    "        \n",
    "        if duplicate_rows > 0:\n",
    "            print(f\"  [FAIL] Found {duplicate_rows} duplicate (unique_id, ds) pairs\")\n",
    "            logger.error(f\"Time series integrity: {duplicate_rows} duplicates\")\n",
    "            report[\"status\"] = \"invalid\"\n",
    "            return report\n",
    "        else:\n",
    "            print(f\"  [OK] No duplicates on (unique_id, ds)\")\n",
    "        \n",
    "        # Check 2-4: Frequency, gaps, DST for each series\n",
    "        for uid in df_sorted[\"unique_id\"].unique():\n",
    "            sub = df_sorted[df_sorted[\"unique_id\"] == uid].copy()\n",
    "            sub = sub.sort_values(\"ds\").reset_index(drop=True)\n",
    "            \n",
    "            # Calculate time differences\n",
    "            time_diffs = sub[\"ds\"].diff()\n",
    "            expected_freq = pd.Timedelta(hours=1)\n",
    "            \n",
    "            # Missing hours (gap > 1 hour)\n",
    "            missing_mask = time_diffs > expected_freq\n",
    "            missing_in_series = missing_mask.sum()\n",
    "            report[\"missing_hours\"] += int(missing_in_series)\n",
    "            \n",
    "            # DST repeated hours (gap = 0, clocks go back)\n",
    "            repeated_mask = time_diffs == pd.Timedelta(0)\n",
    "            repeated_in_series = repeated_mask.sum()\n",
    "            report[\"dst_repeated_hours\"] += int(repeated_in_series)\n",
    "            \n",
    "            # Longest gap\n",
    "            if len(time_diffs) > 0:\n",
    "                max_gap = time_diffs.max()\n",
    "                if pd.notna(max_gap):\n",
    "                    gap_hours = max_gap.total_seconds() / 3600\n",
    "                    report[\"longest_gap_hours\"] = max(\n",
    "                        report[\"longest_gap_hours\"],\n",
    "                        gap_hours\n",
    "                    )\n",
    "                    \n",
    "                    # Record gap locations\n",
    "                    if missing_mask.any():\n",
    "                        gap_indices = sub.index[missing_mask].tolist()\n",
    "                        for idx in gap_indices:\n",
    "                            if idx > 0:\n",
    "                                report[\"gaps_detail\"].append({\n",
    "                                    \"unique_id\": uid,\n",
    "                                    \"before_ds\": sub.loc[idx-1, \"ds\"],\n",
    "                                    \"after_ds\": sub.loc[idx, \"ds\"],\n",
    "                                    \"gap_hours\": gap_hours\n",
    "                                })\n",
    "        \n",
    "        # Report findings\n",
    "        if report[\"duplicate_count\"] > 0:\n",
    "            print(f\"  [FAIL] Found {report['duplicate_count']} duplicates\")\n",
    "            logger.error(f\"Time series integrity FAILED: {report['duplicate_count']} duplicate (unique_id, ds) pairs detected\")\n",
    "            raise ValueError(\n",
    "                f\"Time series data has {report['duplicate_count']} duplicate (unique_id, ds) pairs. \"\n",
    "                f\"This indicates duplicate API responses or data processing errors. \"\n",
    "                f\"Data must be deduplicated before forecasting.\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"  [OK] No duplicates\")\n",
    "        \n",
    "        if report[\"missing_hours\"] > 0:\n",
    "            print(f\"  [FAIL] {report['missing_hours']} missing hours detected\")\n",
    "            logger.error(\n",
    "                f\"Time series integrity FAILED: {report['missing_hours']} missing hours, \"\n",
    "                f\"longest gap {report['longest_gap_hours']:.1f} hours\"\n",
    "            )\n",
    "            gap_summary = \"\\n\".join([\n",
    "                f\"  {g['unique_id']}: {g['before_ds']}  {g['after_ds']} ({g['gap_hours']:.1f} hours)\"\n",
    "                for g in report[\"gaps_detail\"][:5]  # Show first 5 gaps\n",
    "            ])\n",
    "            raise ValueError(\n",
    "                f\"Time series has {report['missing_hours']} missing hours (longest gap: {report['longest_gap_hours']:.1f} hours). \"\n",
    "                f\"Regular hourly frequency is required for forecasting. \"\n",
    "                f\"Gap locations:\\n{gap_summary}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"  [OK] No missing hours (complete frequency)\")\n",
    "        \n",
    "        if report[\"dst_repeated_hours\"] > 0:\n",
    "            print(f\"  [INFO] {report['dst_repeated_hours']} DST repeated hours (clocks back)\")\n",
    "            logger.info(f\"Time series has {report['dst_repeated_hours']} DST repeated hours, which is expected\")\n",
    "        \n",
    "        print(f\"  [OK] Time series integrity validated\")\n",
    "        logger.info(f\"Time series integrity report: {report}\")\n",
    "    \n",
    "    def validate_data(self, df: pd.DataFrame) -> bool:\n",
    "        \"\"\"\n",
    "        STEP 5: Validate data quality.\n",
    "        \n",
    "        Checks:\n",
    "        - No empty DataFrame\n",
    "        - Value column is numeric\n",
    "        - No missing values\n",
    "        - Dates are in order\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if all validations pass\n",
    "        \n",
    "        Example:\n",
    "            >>> is_valid = fetcher.validate_data(df_clean)\n",
    "        \"\"\"\n",
    "        print(f\"\\nStep 5: Validating data...\")\n",
    "        \n",
    "        checks_passed = 0\n",
    "        checks_total = 5\n",
    "        \n",
    "        # Check 1: Not empty\n",
    "        if len(df) > 0:\n",
    "            print(f\"  [OK] Data is not empty: {len(df)} rows\")\n",
    "            checks_passed += 1\n",
    "        else:\n",
    "            print(f\"  [FAIL] Data is empty\")\n",
    "            return False\n",
    "        \n",
    "        # Check 2: Value column exists and is numeric\n",
    "        if \"value\" in df.columns and pd.api.types.is_numeric_dtype(df[\"value\"]):\n",
    "            print(f\"  [OK] Value column is numeric\")\n",
    "            checks_passed += 1\n",
    "        else:\n",
    "            print(f\"  [FAIL] Value column missing or not numeric\")\n",
    "            return False\n",
    "        \n",
    "        # Check 3: No missing values in value column\n",
    "        missing = df[\"value\"].isna().sum()\n",
    "        if missing == 0:\n",
    "            print(f\"  [OK] No missing values in 'value' column\")\n",
    "            checks_passed += 1\n",
    "        else:\n",
    "            print(f\"  [WARN] {missing} missing values in 'value' column\")\n",
    "            checks_passed += 1  # Warning, not failure\n",
    "        \n",
    "        # Check 4: Dates are in order\n",
    "        if df[\"period\"].is_monotonic_increasing:\n",
    "            print(f\"  [OK] Dates are in chronological order\")\n",
    "            checks_passed += 1\n",
    "        else:\n",
    "            print(f\"  [FAIL] Dates are not in order\")\n",
    "            return False\n",
    "        \n",
    "        # Check 5: Value range is reasonable (electricity in MWh)\n",
    "        if df[\"value\"].min() > 0 and df[\"value\"].max() < 1_000_000:\n",
    "            print(f\"  [OK] Value range is reasonable\")\n",
    "            checks_passed += 1\n",
    "        else:\n",
    "            print(f\"  [WARN] Value range seems unusual: {df['value'].min():.0f} to {df['value'].max():.0f}\")\n",
    "            checks_passed += 1  # Warning\n",
    "        \n",
    "        print(f\"\\n  Validation: {checks_passed}/{checks_total} checks passed\")\n",
    "        return True\n",
    "    \n",
    "    def get_stats(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        STEP 6: Calculate summary statistics.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with:\n",
    "            - date_range: (start_date, end_date)\n",
    "            - record_count: Total records\n",
    "            - value_stats: min, max, mean, std\n",
    "            - missing_count: Count of NaN values\n",
    "        \n",
    "        Example:\n",
    "            >>> stats = fetcher.get_stats(df_clean)\n",
    "            >>> print(f\"Date range: {stats['date_range']}\")\n",
    "        \"\"\"\n",
    "        print(f\"\\nStep 6: Calculating statistics...\")\n",
    "        \n",
    "        stats = {\n",
    "            \"date_range\": (df[\"date\"].min(), df[\"date\"].max()),\n",
    "            \"record_count\": len(df),\n",
    "            \"value_stats\": {\n",
    "                \"min\": df[\"value\"].min(),\n",
    "                \"max\": df[\"value\"].max(),\n",
    "                \"mean\": df[\"value\"].mean(),\n",
    "                \"std\": df[\"value\"].std(),\n",
    "            },\n",
    "            \"missing_count\": df[\"value\"].isna().sum(),\n",
    "        }\n",
    "        \n",
    "        print(f\"  Date range: {stats['date_range'][0]} to {stats['date_range'][1]}\")\n",
    "        print(f\"  Record count: {stats['record_count']}\")\n",
    "        print(f\"  Value range: {stats['value_stats']['min']:.0f} to {stats['value_stats']['max']:.0f} MWh\")\n",
    "        print(f\"  Value mean: {stats['value_stats']['mean']:.0f} MWh\")\n",
    "        print(f\"  Value std: {stats['value_stats']['std']:.0f} MWh\")\n",
    "        print(f\"  Missing values: {stats['missing_count']}\")\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def prepare_for_forecasting(\n",
    "        self, \n",
    "        df: pd.DataFrame,\n",
    "        unique_id: str = \"1\"\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Prepare data for statsforecast/mlforecast by reformatting columns.\n",
    "        \n",
    "        Statsforecast requires: unique_id, ds (timestamp), y (values)\n",
    "        \n",
    "        Args:\n",
    "            df: Cleaned DataFrame from prepare_data()\n",
    "            unique_id: Series identifier (default: fuel type like \"NG\")\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with statsforecast format (unique_id, ds, y)\n",
    "        \n",
    "        Example:\n",
    "            >>> df_clean = fetcher.prepare_data(df_raw)\n",
    "            >>> df_forecast = fetcher.prepare_for_forecasting(df_clean)\n",
    "        \"\"\"\n",
    "        # Validation: check required columns\n",
    "        required_cols = ['period', 'value']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            logger.error(f\"Missing required columns: {missing_cols}\")\n",
    "            raise ValueError(\n",
    "                f\"prepare_for_forecasting requires columns {required_cols}, \"\n",
    "                f\"but found: {df.columns.tolist()}. \"\n",
    "                f\"Ensure prepare_data() completed successfully.\"\n",
    "            )\n",
    "        \n",
    "        # Validation: check for NaN values (should not exist after prepare_data)\n",
    "        nan_count_period = df['period'].isna().sum()\n",
    "        nan_count_value = df['value'].isna().sum()\n",
    "        \n",
    "        if nan_count_period > 0:\n",
    "            logger.error(f\"Found {nan_count_period} NaN values in period column\")\n",
    "            raise ValueError(\n",
    "                f\"Cannot prepare forecasting data with {nan_count_period} NaN values in period. \"\n",
    "                f\"This indicates incomplete datetime parsing. \"\n",
    "                f\"Run validate_data() and check prepare_data() error logs.\"\n",
    "            )\n",
    "        \n",
    "        if nan_count_value > 0:\n",
    "            logger.error(f\"Found {nan_count_value} NaN values in value column\")\n",
    "            raise ValueError(\n",
    "                f\"Cannot prepare forecasting data with {nan_count_value} NaN values in value. \"\n",
    "                f\"This indicates failed numeric conversion. \"\n",
    "                f\"Run validate_data() and check prepare_data() error logs.\"\n",
    "            )\n",
    "        \n",
    "        df_forecast = df.copy()\n",
    "        df_forecast.columns = [col.lower() for col in df_forecast.columns]\n",
    "        \n",
    "        # Rename columns for statsforecast\n",
    "        df_forecast['ds'] = df_forecast['period']\n",
    "        df_forecast['y'] = df_forecast['value']\n",
    "        df_forecast['unique_id'] = unique_id\n",
    "        \n",
    "        # Keep only required columns\n",
    "        df_forecast = df_forecast[['unique_id', 'ds', 'y']].reset_index(drop=True)\n",
    "        \n",
    "        logger.info(f\"Prepared {len(df_forecast)} records for forecasting with unique_id={unique_id}\")\n",
    "        \n",
    "        return df_forecast\n",
    "    \n",
    "    def train_test_split(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        test_hours: int = 72\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Split data into training and testing sets.\n",
    "        \n",
    "        Leaves last N hours for testing, rest for training.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with 'ds' (datetime) column\n",
    "            test_hours: Number of hours to reserve for testing (default: 72)\n",
    "        \n",
    "        Returns:\n",
    "            (train_df, test_df)\n",
    "        \n",
    "        Example:\n",
    "            >>> train_df, test_df = fetcher.train_test_split(df_forecast, test_hours=168)\n",
    "            >>> print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n",
    "        \"\"\"\n",
    "        df = df.sort_values('ds').reset_index(drop=True)\n",
    "        \n",
    "        # Calculate split point\n",
    "        split_point = df['ds'].max() - timedelta(hours=test_hours)\n",
    "        \n",
    "        train_df = df[df['ds'] <= split_point].reset_index(drop=True)\n",
    "        test_df = df[df['ds'] > split_point].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nTrain/Test Split:\")\n",
    "        print(f\"  Training set: {len(train_df)} records\")\n",
    "        print(f\"  Testing set: {len(test_df)} records\")\n",
    "        print(f\"  Split point: {split_point}\")\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    def build_models(self) -> List:\n",
    "        \"\"\"\n",
    "        Build a list of forecasting models for statsforecast.\n",
    "        \n",
    "        Models included:\n",
    "        - AutoARIMA: Auto-tuned ARIMA model\n",
    "        - SeasonalNaive: Baseline seasonal model (same value from year ago)\n",
    "        - DynamicOptimizedTheta: Theta model with automatic optimization\n",
    "        - HoltWinters: Exponential smoothing model\n",
    "        - MSTL_ARIMA: Multi-seasonal trend with ARIMA trend forecaster\n",
    "        - MSTL_HoltWinters: Multi-seasonal trend with HoltWinters trend forecaster\n",
    "        \n",
    "        Returns:\n",
    "            List of statsforecast model objects\n",
    "        \n",
    "        Example:\n",
    "            >>> from statsforecast import StatsForecast\n",
    "            >>> models = fetcher.build_models()\n",
    "            >>> sf = StatsForecast(models=models, freq='h')\n",
    "        \"\"\"\n",
    "        from statsforecast.models import (MSTL, AutoARIMA,\n",
    "                                          DynamicOptimizedTheta, HoltWinters,\n",
    "                                          SeasonalNaive)\n",
    "        \n",
    "        models = [\n",
    "            AutoARIMA(season_length=24),\n",
    "            SeasonalNaive(season_length=24),\n",
    "            DynamicOptimizedTheta(season_length=24),\n",
    "            HoltWinters(season_length=24),\n",
    "            MSTL(season_length=[24, 24 * 7], trend_forecaster=AutoARIMA(), alias=\"MSTL_ARIMA\"),\n",
    "            MSTL(season_length=[24, 24 * 7], trend_forecaster=HoltWinters(), alias=\"MSTL_HoltWinters\"),\n",
    "        ]\n",
    "        \n",
    "        return models\n",
    "    \n",
    "    def forecast(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        horizon: int = 72,\n",
    "        confidence_level: int = 95\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create forecasts using StatsForecast.\n",
    "        \n",
    "        Args:\n",
    "            train_df: Training DataFrame with unique_id, ds, y columns\n",
    "            horizon: Number of steps to forecast (default: 72 hours)\n",
    "            confidence_level: Prediction interval level (default: 95%)\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with forecasts and prediction intervals\n",
    "        \n",
    "        Example:\n",
    "            >>> forecast_df = fetcher.forecast(train_df, horizon=168)\n",
    "            >>> print(forecast_df.head())\n",
    "        \"\"\"\n",
    "        from statsforecast import StatsForecast\n",
    "        from statsforecast.models import AutoARIMA\n",
    "        \n",
    "        models = self.build_models()\n",
    "        \n",
    "        # Initialize StatsForecast object\n",
    "        sf = StatsForecast(\n",
    "            models=models,\n",
    "            freq='h',  # Hourly data (lowercase for pandas compatibility)\n",
    "            fallback_model=AutoARIMA(),\n",
    "            n_jobs=-1  # Use all available cores\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTraining {len(models)} models...\")\n",
    "        print(f\"  Models: {', '.join([type(m).__name__ for m in models])}\")\n",
    "        print(f\"  Horizon: {horizon} hours\")\n",
    "        print(f\"  Confidence level: {confidence_level}%\")\n",
    "        \n",
    "        # Generate forecast (note: h comes first in signature)\n",
    "        forecast_df = sf.forecast(h=horizon, df=train_df, level=[confidence_level])\n",
    "        \n",
    "        print(f\"  [OK] Forecast generated: {len(forecast_df)} predictions\")\n",
    "        \n",
    "        return forecast_df\n",
    "    \n",
    "    def evaluate_forecast(\n",
    "        self,\n",
    "        forecast_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        train_df: Optional[pd.DataFrame] = None,\n",
    "        season_length: int = 24\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Evaluate forecast performance against test data.\n",
    "\n",
    "        Calculates: MAPE, RMSE, MASE, and prediction interval coverage\n",
    "\n",
    "        Critical features:\n",
    "        - Merge on (unique_id, ds) for multi-series correctness\n",
    "        - All metrics computed on valid rows only (NaN-aware)\n",
    "        - Coverage denominator = valid rows (not total rows)\n",
    "        - MASE scales error relative to seasonal naive baseline\n",
    "\n",
    "        Args:\n",
    "            forecast_df: DataFrame from forecast() method\n",
    "            test_df: Test partition from train_test_split()\n",
    "            train_df: Training data (required for MASE calculation)\n",
    "            season_length: Seasonal period for MASE (default: 24 hours)\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with performance metrics for each model\n",
    "\n",
    "        Example:\n",
    "            >>> metrics = fetcher.evaluate_forecast(forecast_df, test_df, train_df)\n",
    "            >>> print(metrics.sort_values('rmse'))\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import (mean_absolute_percentage_error,\n",
    "                                     mean_squared_error)\n",
    "\n",
    "        # Merge forecast with test data on BOTH unique_id and ds (critical for multi-series)\n",
    "        fc = forecast_df.merge(\n",
    "            test_df,\n",
    "            how=\"left\",\n",
    "            on=[\"unique_id\", \"ds\"]  #  BOTH keys for correctness\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Evaluation merge: {len(forecast_df)} forecast rows, {len(test_df)} test rows, {len(fc)} merged rows\")\n",
    "\n",
    "        # Helper functions for metrics (NaN-aware)\n",
    "        def mape(y, yhat):\n",
    "            \"\"\"Mean Absolute Percentage Error (ignoring NaNs)\"\"\"\n",
    "            mask = y.notna() & yhat.notna()\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "            return mean_absolute_percentage_error(y[mask], yhat[mask])\n",
    "\n",
    "        def rmse(y, yhat):\n",
    "            \"\"\"Root Mean Squared Error (ignoring NaNs)\"\"\"\n",
    "            mask = y.notna() & yhat.notna()\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "            return np.sqrt(mean_squared_error(y[mask], yhat[mask]))\n",
    "\n",
    "        def mase(y, yhat, y_train, season_length=24):\n",
    "            \"\"\"\n",
    "            Mean Absolute Scaled Error.\n",
    "\n",
    "            Scales the MAE by the MAE of a seasonal naive forecast on training data.\n",
    "            MASE < 1 means the model beats seasonal naive.\n",
    "            MASE > 1 means seasonal naive is better.\n",
    "\n",
    "            Args:\n",
    "                y: Actual test values\n",
    "                yhat: Predicted values\n",
    "                y_train: Training data for computing naive baseline\n",
    "                season_length: Seasonal period (default: 24 for hourly data)\n",
    "            \"\"\"\n",
    "            if y_train is None or len(y_train) < season_length + 1:\n",
    "                return np.nan\n",
    "\n",
    "            mask = y.notna() & yhat.notna()\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "\n",
    "            # MAE of the forecast\n",
    "            mae_forecast = np.mean(np.abs(y[mask].values - yhat[mask].values))\n",
    "\n",
    "            # MAE of seasonal naive on training data\n",
    "            # Seasonal naive: y_t = y_{t - season_length}\n",
    "            y_train_arr = y_train[\"y\"].values\n",
    "            naive_errors = np.abs(y_train_arr[season_length:] - y_train_arr[:-season_length])\n",
    "            mae_naive = np.mean(naive_errors)\n",
    "\n",
    "            if mae_naive < 1e-10:  # Avoid division by zero\n",
    "                return np.nan\n",
    "\n",
    "            return mae_forecast / mae_naive\n",
    "\n",
    "        def coverage(y, lower, upper):\n",
    "            \"\"\"Prediction interval coverage (ignoring NaNs, denominator = valid rows)\"\"\"\n",
    "            mask = y.notna() & lower.notna() & upper.notna()\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "            within = ((y[mask] >= lower[mask]) & (y[mask] <= upper[mask])).sum()\n",
    "            return (within / mask.sum()) * 100  # denominator = valid rows only\n",
    "\n",
    "        # Get model names (exclude metadata columns and interval bounds)\n",
    "        model_cols = [col for col in forecast_df.columns\n",
    "                     if col not in ['unique_id', 'ds'] and\n",
    "                     not col.endswith('-lo-95') and\n",
    "                     not col.endswith('-hi-95')]\n",
    "\n",
    "        # Calculate metrics for each model\n",
    "        rows = []\n",
    "        for model in model_cols:\n",
    "            y = fc[\"y\"]\n",
    "            yhat = fc[model]\n",
    "\n",
    "            # Count valid rows for this model\n",
    "            mask = y.notna() & yhat.notna()\n",
    "            valid_count = mask.sum()\n",
    "\n",
    "            rows.append({\n",
    "                \"model\": model,\n",
    "                \"mape\": mape(y=y, yhat=yhat),\n",
    "                \"rmse\": rmse(y=y, yhat=yhat),\n",
    "                \"mase\": mase(y=y, yhat=yhat, y_train=train_df, season_length=season_length),\n",
    "                \"coverage\": coverage(\n",
    "                    y=y,\n",
    "                    lower=fc[f\"{model}-lo-95\"],\n",
    "                    upper=fc[f\"{model}-hi-95\"],\n",
    "                ),\n",
    "                \"valid_rows\": valid_count,\n",
    "            })\n",
    "\n",
    "        fc_performance = pd.DataFrame(rows).sort_values('rmse')\n",
    "\n",
    "        # Report merge quality\n",
    "        valid_total = fc[\"y\"].notna().sum()\n",
    "        print(f\"\\nEvaluation Metrics (on {valid_total} valid rows out of {len(fc)} total):\")\n",
    "        print(f\"{'Model':<20} {'MAPE':<8} {'RMSE':<8} {'MASE':<8} {'Coverage':<10} {'Valid':<8}\")\n",
    "        print(\"-\" * 62)\n",
    "        for _, row in fc_performance.iterrows():\n",
    "            coverage_str = f\"{row['coverage']:.1f}%\" if pd.notna(row['coverage']) else \"N/A\"\n",
    "            mase_str = f\"{row['mase']:.3f}\" if pd.notna(row['mase']) else \"N/A\"\n",
    "            print(f\"{row['model']:<20} {row['mape']:.4f}  {row['rmse']:<8.0f} {mase_str:<8} {coverage_str:<10} {int(row['valid_rows']):<8}\")\n",
    "        \n",
    "        logger.info(f\"Evaluation complete: {valid_total} valid rows, {len(fc_performance)} models evaluated\")\n",
    "\n",
    "        return fc_performance\n",
    "\n",
    "    def cross_validate(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        config: Optional[ExperimentConfig] = None,\n",
    "        horizon: int = 24,\n",
    "        n_windows: int = 5,\n",
    "        step_size: int = 168,\n",
    "        confidence_level: int = 95\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Run rolling origin cross-validation for robust model evaluation.\n",
    "\n",
    "        Instead of a single train/test split, this creates multiple windows:\n",
    "        - Window 1: Train on data up to t1, test on t1 to t1+horizon\n",
    "        - Window 2: Train on data up to t2, test on t2 to t2+horizon\n",
    "        - ... and so on\n",
    "\n",
    "        This gives you a better estimate of how your model will perform\n",
    "        on future unseen data.\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame with unique_id, ds, y columns\n",
    "            config: ExperimentConfig (overrides other params if provided)\n",
    "            horizon: Forecast horizon in hours (default: 24)\n",
    "            n_windows: Number of CV windows (default: 5)\n",
    "            step_size: Hours between windows (default: 168 = 1 week)\n",
    "            confidence_level: Prediction interval level (default: 95)\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (cv_results_df, leaderboard_df)\n",
    "            - cv_results_df: Raw predictions for each cutoff\n",
    "            - leaderboard_df: Aggregated metrics per model\n",
    "\n",
    "        Example:\n",
    "            >>> cv_results, leaderboard = fetcher.cross_validate(\n",
    "            ...     df_forecast,\n",
    "            ...     horizon=24,\n",
    "            ...     n_windows=5,\n",
    "            ...     step_size=168\n",
    "            ... )\n",
    "            >>> print(leaderboard)\n",
    "        \"\"\"\n",
    "        from statsforecast import StatsForecast\n",
    "\n",
    "        # Use config if provided\n",
    "        if config is not None:\n",
    "            horizon = config.horizon\n",
    "            n_windows = config.n_windows\n",
    "            step_size = config.step_size\n",
    "            confidence_level = config.confidence_level\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"CROSS-VALIDATION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"  Horizon: {horizon} hours\")\n",
    "        print(f\"  Windows: {n_windows}\")\n",
    "        print(f\"  Step size: {step_size} hours\")\n",
    "\n",
    "        # Build models\n",
    "        models = self.build_models()\n",
    "\n",
    "        # Create StatsForecast object\n",
    "        sf = StatsForecast(\n",
    "            models=models,\n",
    "            freq='h',\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "\n",
    "        # Run cross-validation\n",
    "        # This is the key statsforecast method for backtesting\n",
    "        print(f\"\\n  Running {n_windows} CV windows...\")\n",
    "        cv_df = sf.cross_validation(\n",
    "            df=df,\n",
    "            h=horizon,\n",
    "            step_size=step_size,\n",
    "            n_windows=n_windows,\n",
    "            level=[confidence_level],\n",
    "        )\n",
    "\n",
    "        print(f\"  [OK] CV complete: {len(cv_df)} total predictions\")\n",
    "        print(f\"  Cutoff dates: {cv_df['cutoff'].nunique()} unique\")\n",
    "\n",
    "        # Compute metrics per cutoff per model\n",
    "        cv_metrics = []\n",
    "        model_names = [type(m).__name__ if not hasattr(m, 'alias') else m.alias\n",
    "                       for m in models]\n",
    "\n",
    "        for cutoff in cv_df[\"cutoff\"].unique():\n",
    "            window_df = cv_df[cv_df[\"cutoff\"] == cutoff]\n",
    "            y_true = window_df[\"y\"].values\n",
    "\n",
    "            for model in model_names:\n",
    "                if model not in window_df.columns:\n",
    "                    continue\n",
    "\n",
    "                y_pred = window_df[model].values\n",
    "                mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "\n",
    "                if mask.sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                # RMSE\n",
    "                rmse_val = np.sqrt(np.mean((y_true[mask] - y_pred[mask]) ** 2))\n",
    "\n",
    "                # MAPE\n",
    "                mape_val = 100 * np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "                # Coverage\n",
    "                lo_col = f\"{model}-lo-{confidence_level}\"\n",
    "                hi_col = f\"{model}-hi-{confidence_level}\"\n",
    "                coverage_val = np.nan\n",
    "                if lo_col in window_df.columns and hi_col in window_df.columns:\n",
    "                    lo = window_df[lo_col].values\n",
    "                    hi = window_df[hi_col].values\n",
    "                    within = ((y_true >= lo) & (y_true <= hi)).sum()\n",
    "                    coverage_val = 100 * within / len(y_true)\n",
    "\n",
    "                cv_metrics.append({\n",
    "                    \"cutoff\": cutoff,\n",
    "                    \"model\": model,\n",
    "                    \"rmse\": rmse_val,\n",
    "                    \"mape\": mape_val,\n",
    "                    \"coverage\": coverage_val,\n",
    "                })\n",
    "\n",
    "        cv_metrics_df = pd.DataFrame(cv_metrics)\n",
    "\n",
    "        # Create leaderboard by aggregating across windows\n",
    "        leaderboard = cv_metrics_df.groupby(\"model\").agg({\n",
    "            \"rmse\": [\"mean\", \"std\"],\n",
    "            \"mape\": [\"mean\", \"std\"],\n",
    "            \"coverage\": \"mean\",\n",
    "        }).round(2)\n",
    "\n",
    "        # Flatten column names\n",
    "        leaderboard.columns = [\"_\".join(col).strip() for col in leaderboard.columns.values]\n",
    "        leaderboard = leaderboard.sort_values(\"rmse_mean\").reset_index()\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"LEADERBOARD (aggregated across {n_windows} windows)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"{'Model':<20} {'RMSE':<12} {'MAPE':<12} {'Coverage':<10}\")\n",
    "        print(\"-\" * 54)\n",
    "        for _, row in leaderboard.iterrows():\n",
    "            rmse_str = f\"{row['rmse_mean']:.0f}  {row['rmse_std']:.0f}\"\n",
    "            mape_str = f\"{row['mape_mean']:.2f}  {row['mape_std']:.2f}\"\n",
    "            cov_str = f\"{row['coverage_mean']:.1f}%\"\n",
    "            print(f\"{row['model']:<20} {rmse_str:<12} {mape_str:<12} {cov_str:<10}\")\n",
    "\n",
    "        return cv_df, leaderboard\n",
    "\n",
    "    def register_best_model(\n",
    "        self,\n",
    "        leaderboard: pd.DataFrame,\n",
    "        model_name: str = None,\n",
    "        experiment_name: str = \"eia_forecasting\",\n",
    "        alias: str = \"champion\"\n",
    "    ) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Register the best model from cross-validation to MLflow Model Registry.\n",
    "\n",
    "        The Model Registry lets you:\n",
    "        - Track model versions over time\n",
    "        - Assign aliases like \"champion\" (production) or \"candidate\" (staging)\n",
    "        - Manage model lifecycle (staging -> production -> archived)\n",
    "\n",
    "        Args:\n",
    "            leaderboard: DataFrame from cross_validate()\n",
    "            model_name: Override best model selection (default: lowest RMSE)\n",
    "            experiment_name: MLflow experiment name\n",
    "            alias: Alias to assign (\"champion\", \"candidate\", etc.)\n",
    "\n",
    "        Returns:\n",
    "            Model version string if successful, None otherwise\n",
    "\n",
    "        Example:\n",
    "            >>> cv_df, leaderboard = fetcher.cross_validate(df)\n",
    "            >>> version = fetcher.register_best_model(leaderboard, alias=\"champion\")\n",
    "        \"\"\"\n",
    "        if not MLFLOW_AVAILABLE:\n",
    "            print(\"  [SKIP] MLflow not available - cannot register model\")\n",
    "            return None\n",
    "\n",
    "        # Select best model\n",
    "        if model_name is None:\n",
    "            model_name = leaderboard.iloc[0][\"model\"]\n",
    "\n",
    "        best_metrics = leaderboard[leaderboard[\"model\"] == model_name].iloc[0]\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"MODEL REGISTRY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"  Best model: {model_name}\")\n",
    "        print(f\"  RMSE: {best_metrics['rmse_mean']:.0f}\")\n",
    "        print(f\"  Registering with alias: {alias}\")\n",
    "\n",
    "        # Set experiment\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"register_{model_name}\"):\n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"rmse_mean\", best_metrics[\"rmse_mean\"])\n",
    "            mlflow.log_metric(\"rmse_std\", best_metrics[\"rmse_std\"])\n",
    "            mlflow.log_metric(\"mape_mean\", best_metrics[\"mape_mean\"])\n",
    "            mlflow.log_metric(\"coverage_mean\", best_metrics[\"coverage_mean\"])\n",
    "            mlflow.log_param(\"model_name\", model_name)\n",
    "\n",
    "            # Create a simple model artifact (the model name for now)\n",
    "            # In production, you'd save the actual fitted model object\n",
    "            model_info = {\n",
    "                \"model_name\": model_name,\n",
    "                \"metrics\": {\n",
    "                    \"rmse_mean\": float(best_metrics[\"rmse_mean\"]),\n",
    "                    \"mape_mean\": float(best_metrics[\"mape_mean\"]),\n",
    "                    \"coverage_mean\": float(best_metrics[\"coverage_mean\"]),\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Log as artifact\n",
    "            import json\n",
    "            import tempfile\n",
    "            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n",
    "                json.dump(model_info, f)\n",
    "                mlflow.log_artifact(f.name, \"model\")\n",
    "\n",
    "            # Register the model\n",
    "            registered_model_name = f\"{experiment_name}_{model_name}\"\n",
    "\n",
    "            # Use mlflow.register_model to add to registry\n",
    "            run_id = mlflow.active_run().info.run_id\n",
    "            model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "            try:\n",
    "                # Register the model\n",
    "                result = mlflow.register_model(model_uri, registered_model_name)\n",
    "                version = result.version\n",
    "\n",
    "                # Set alias (champion/candidate)\n",
    "                client = mlflow.tracking.MlflowClient()\n",
    "                client.set_registered_model_alias(registered_model_name, alias, version)\n",
    "\n",
    "                print(f\"  [OK] Registered: {registered_model_name} v{version}\")\n",
    "                print(f\"  [OK] Alias '{alias}' assigned to v{version}\")\n",
    "\n",
    "                logger.info(f\"Model registered: {registered_model_name} v{version} with alias {alias}\")\n",
    "\n",
    "                return f\"{registered_model_name}@{alias}\"\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Model registration failed: {e}\")\n",
    "                print(f\"  [WARN] Registration failed: {e}\")\n",
    "                return None\n",
    "\n",
    "    def _create_plot(self, test_df: pd.DataFrame, forecast_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Create an interactive plotly visualization of forecast vs actuals.\n",
    "        \n",
    "        Args:\n",
    "            test_df: Test partition with actual values\n",
    "            forecast_df: Forecast predictions\n",
    "        \n",
    "        Returns:\n",
    "            Plotly Figure object\n",
    "        \"\"\"\n",
    "        import plotly.graph_objects as go\n",
    "\n",
    "        # Merge data\n",
    "        merged = test_df.merge(forecast_df, on=['unique_id', 'ds'])\n",
    "        merged = merged.sort_values('ds')\n",
    "        \n",
    "        # Create figure\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Add actual values\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=merged['ds'],\n",
    "            y=merged['y'],\n",
    "            mode='lines',\n",
    "            name='Actual',\n",
    "            line=dict(color='blue', width=2)\n",
    "        ))\n",
    "        \n",
    "        # Add forecast from best model (MSTL_ARIMA)\n",
    "        if 'MSTL_ARIMA' in merged.columns:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=merged['ds'],\n",
    "                y=merged['MSTL_ARIMA'],\n",
    "                mode='lines',\n",
    "                name='MSTL_ARIMA (Best)',\n",
    "                line=dict(color='red', width=2, dash='dash')\n",
    "            ))\n",
    "            \n",
    "            # Add 95% confidence interval if available\n",
    "            if 'MSTL_ARIMA-hi-95' in merged.columns and 'MSTL_ARIMA-lo-95' in merged.columns:\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=merged['ds'].tolist() + merged['ds'].tolist()[::-1],\n",
    "                    y=merged['MSTL_ARIMA-hi-95'].tolist() + merged['MSTL_ARIMA-lo-95'].tolist()[::-1],\n",
    "                    fill='toself',\n",
    "                    fillcolor='rgba(255, 0, 0, 0.2)',\n",
    "                    line=dict(color='rgba(255, 0, 0, 0)'),\n",
    "                    name='95% Confidence Interval'\n",
    "                ))\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title='EIA Electricity Generation: Forecast vs Actual',\n",
    "            xaxis_title='Date',\n",
    "            yaxis_title='Generation (MWh)',\n",
    "            hovermode='x unified',\n",
    "            height=400,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def run_experiment(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        experiment_name: str,\n",
    "        test_hours: int = 72,\n",
    "        models_to_test: Optional[List[str]] = None,\n",
    "        track_with_mlflow: bool = False\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Run a complete forecasting experiment with model evaluation.\n",
    "        \n",
    "        Args:\n",
    "            df: Cleaned DataFrame from full_pipeline()\n",
    "            experiment_name: Name for this experiment\n",
    "            test_hours: Hours to reserve for testing (default: 72)\n",
    "            models_to_test: List of model names to test (None = all)\n",
    "            track_with_mlflow: Whether to log to MLflow (default: False)\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with experiment results including:\n",
    "            - experiment_name: Name of experiment\n",
    "            - timestamp: When experiment was run\n",
    "            - data_shape: (rows, columns) of data used\n",
    "            - train_size: Number of training records\n",
    "            - test_size: Number of testing records\n",
    "            - metrics: Performance metrics for each model\n",
    "            - best_model: Name of best performing model\n",
    "            - results: Full results DataFrame\n",
    "        \n",
    "        Example:\n",
    "            >>> results = fetcher.run_experiment(df, \"exp1_baseline\")\n",
    "            >>> print(results['best_model'])\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting experiment: {experiment_name} with test_hours={test_hours}\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(f\"EXPERIMENT: {experiment_name}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Start MLflow run if enabled\n",
    "        if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "            mlflow.start_run(run_name=experiment_name)\n",
    "            mlflow.log_param(\"experiment_name\", experiment_name)\n",
    "            mlflow.log_param(\"test_hours\", test_hours)\n",
    "            logger.info(\"MLflow run started for experiment\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare data\n",
    "            logger.info(\"Preparing data for experiment\")\n",
    "            print(f\"\\nPreparing data for experiment...\")\n",
    "            df_forecast = self.prepare_for_forecasting(df)\n",
    "            train_df, test_df = self.train_test_split(df_forecast, test_hours=test_hours)\n",
    "            \n",
    "            # Log data info\n",
    "            logger.info(f\"Data shape: {df.shape}, Train: {len(train_df)}, Test: {len(test_df)}\")\n",
    "            print(f\"  Data shape: {df.shape}\")\n",
    "            print(f\"  Training records: {len(train_df)}\")\n",
    "            print(f\"  Testing records: {len(test_df)}\")\n",
    "            \n",
    "            if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                mlflow.log_param(\"data_rows\", df.shape[0])\n",
    "                mlflow.log_param(\"train_size\", len(train_df))\n",
    "                mlflow.log_param(\"test_size\", len(test_df))\n",
    "            \n",
    "            # Train and forecast\n",
    "            logger.info(\"Training models\")\n",
    "            print(f\"\\nTraining models...\")\n",
    "            forecast_df = self.forecast(train_df, horizon=len(test_df))\n",
    "            \n",
    "            # Evaluate (pass train_df for MASE calculation)\n",
    "            logger.info(\"Evaluating model performance\")\n",
    "            print(f\"\\nEvaluating performance...\")\n",
    "            metrics_df = self.evaluate_forecast(forecast_df, test_df, train_df=train_df)\n",
    "            \n",
    "            # Log metrics to MLflow\n",
    "            if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                for _, row in metrics_df.iterrows():\n",
    "                    model_name = row['model']\n",
    "                    mlflow.log_metrics({\n",
    "                        f\"{model_name}_mape\": row['mape'],\n",
    "                        f\"{model_name}_rmse\": row['rmse'],\n",
    "                        f\"{model_name}_coverage\": row['coverage'],\n",
    "                    })\n",
    "            \n",
    "            # Identify best model\n",
    "            best_model = metrics_df.iloc[0]['model']\n",
    "            best_rmse = metrics_df.iloc[0]['rmse']\n",
    "            \n",
    "            logger.info(f\"Experiment {experiment_name} complete - Best model: {best_model}, RMSE: {best_rmse:.0f}\")\n",
    "            \n",
    "            # Compile results\n",
    "            experiment_results = {\n",
    "                \"experiment_name\": experiment_name,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"data_shape\": df.shape,\n",
    "                \"train_size\": len(train_df),\n",
    "                \"test_size\": len(test_df),\n",
    "                \"metrics\": metrics_df,\n",
    "                \"best_model\": best_model,\n",
    "                \"best_rmse\": best_rmse,\n",
    "                \"results\": metrics_df\n",
    "            }\n",
    "            \n",
    "            # Log summary\n",
    "            if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                mlflow.log_metric(\"best_rmse\", best_rmse)\n",
    "                mlflow.log_param(\"best_model\", best_model)\n",
    "            \n",
    "            print(f\"\\n[OK] Experiment complete!\")\n",
    "            print(f\"  Best model: {best_model}\")\n",
    "            print(f\"  Best RMSE: {best_rmse:.0f}\")\n",
    "            \n",
    "            return experiment_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Experiment {experiment_name} failed: {str(e)}\", exc_info=True)\n",
    "            if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                mlflow.log_param(\"error\", str(e))\n",
    "            raise\n",
    "        \n",
    "        finally:\n",
    "            if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                mlflow.end_run()\n",
    "                logger.info(f\"MLflow run ended for experiment {experiment_name}\")\n",
    "    \n",
    "    def save_datasets(\n",
    "        self,\n",
    "        raw_df: pd.DataFrame,\n",
    "        clean_df: pd.DataFrame,\n",
    "        integrity_report: Dict,\n",
    "        output_dir: str = \"data\",\n",
    "        pull_params: Optional[Dict] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Save datasets with versioning and metadata for reproducibility.\n",
    "        \n",
    "        Creates:\n",
    "        - raw.parquet: Unmodified API response\n",
    "        - clean.parquet: After prepare + validate\n",
    "        - metadata.json: Pull parameters, timestamps, row counts, integrity report\n",
    "        \n",
    "        This enables:\n",
    "        - Reproducibility across experiments\n",
    "        - Data lineage tracking\n",
    "        - Debugging with raw vs clean comparison\n",
    "        - Integrity validation history\n",
    "        \n",
    "        Args:\n",
    "            raw_df: Raw DataFrame from pull_data()\n",
    "            clean_df: Cleaned DataFrame from prepare_data()\n",
    "            integrity_report: Report from validate_time_series_integrity()\n",
    "            output_dir: Directory to save datasets (default: \"data\")\n",
    "            pull_params: Dictionary of pull_data() parameters for metadata\n",
    "        \n",
    "        Returns:\n",
    "            Path to saved metadata file\n",
    "        \n",
    "        Example:\n",
    "            >>> metadata_path = fetcher.save_datasets(\n",
    "            ...     raw_df, clean_df, integrity_report,\n",
    "            ...     pull_params={\"start_date\": \"2024-12-01\", \"respondent\": \"US48\"}\n",
    "            ... )\n",
    "        \"\"\"\n",
    "        import json\n",
    "        import os\n",
    "\n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Generate timestamp for this version\n",
    "        timestamp = datetime.now(tz=pytz.UTC).isoformat()\n",
    "        \n",
    "        # Build metadata\n",
    "        metadata = {\n",
    "            \"version\": \"1.0\",\n",
    "            \"timestamp\": timestamp,\n",
    "            \"pull_parameters\": pull_params or {},\n",
    "            \"raw_row_count\": len(raw_df),\n",
    "            \"clean_row_count\": len(clean_df),\n",
    "            \"validation_status\": \"passed\" if integrity_report.get(\"status\") == \"valid\" else \"failed\",\n",
    "            \"integrity_report\": {\n",
    "                \"duplicate_count\": integrity_report.get(\"duplicate_count\", 0),\n",
    "                \"missing_hours\": integrity_report.get(\"missing_hours\", 0),\n",
    "                \"longest_gap_hours\": integrity_report.get(\"longest_gap_hours\", 0),\n",
    "                \"dst_repeated_hours\": integrity_report.get(\"dst_repeated_hours\", 0),\n",
    "            },\n",
    "            \"columns\": {\n",
    "                \"raw\": list(raw_df.columns),\n",
    "                \"clean\": list(clean_df.columns),\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save raw data\n",
    "        raw_path = os.path.join(output_dir, \"raw.parquet\")\n",
    "        raw_df.to_parquet(raw_path, index=False)\n",
    "        print(f\"  [OK] Raw data saved: {raw_path}\")\n",
    "        logger.info(f\"Raw data saved: {raw_path} ({len(raw_df)} rows)\")\n",
    "        \n",
    "        # Save clean data\n",
    "        clean_path = os.path.join(output_dir, \"clean.parquet\")\n",
    "        clean_df.to_parquet(clean_path, index=False)\n",
    "        print(f\"  [OK] Clean data saved: {clean_path}\")\n",
    "        logger.info(f\"Clean data saved: {clean_path} ({len(clean_df)} rows)\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata_path = os.path.join(output_dir, \"metadata.json\")\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            json.dump(metadata, f, indent=2, default=str)\n",
    "        print(f\"  [OK] Metadata saved: {metadata_path}\")\n",
    "        logger.info(f\"Metadata saved: {metadata_path}\")\n",
    "        \n",
    "        return metadata_path\n",
    "    \n",
    "    def compare_experiments(self, experiments: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compare results from multiple experiments.\n",
    "        \n",
    "        Args:\n",
    "            experiments: List of experiment result dictionaries\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame comparing best models from each experiment\n",
    "        \n",
    "        Example:\n",
    "            >>> exp1 = fetcher.run_experiment(df, \"exp1\")\n",
    "            >>> exp2 = fetcher.run_experiment(df, \"exp2\")\n",
    "            >>> comparison = fetcher.compare_experiments([exp1, exp2])\n",
    "        \"\"\"\n",
    "        logger.info(f\"Comparing {len(experiments)} experiments\")\n",
    "        \n",
    "        comparison_rows = []\n",
    "        \n",
    "        for exp in experiments:\n",
    "            best_row = exp['results'].iloc[0]\n",
    "            comparison_rows.append({\n",
    "                \"experiment\": exp[\"experiment_name\"],\n",
    "                \"best_model\": exp[\"best_model\"],\n",
    "                \"mape\": best_row['mape'],\n",
    "                \"rmse\": best_row['rmse'],\n",
    "                \"coverage\": best_row['coverage'],\n",
    "                \"timestamp\": exp[\"timestamp\"]\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_rows).sort_values('rmse')\n",
    "        \n",
    "        # Log comparison results\n",
    "        logger.info(\"Experiment comparison results:\")\n",
    "        for _, row in comparison_df.iterrows():\n",
    "            logger.info(f\"  {row['experiment']}: {row['best_model']} (RMSE: {row['rmse']:.0f}, MAPE: {row['mape']:.4f})\")\n",
    "        \n",
    "        best_exp = comparison_df.iloc[0]\n",
    "        logger.info(f\"Best overall: {best_exp['experiment']} with {best_exp['best_model']} (RMSE: {best_exp['rmse']:.0f})\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"EXPERIMENT COMPARISON\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\n{'Experiment':<25} {'Best Model':<20} {'RMSE':<10} {'MAPE':<10}\")\n",
    "        print(\"-\" * 65)\n",
    "        for _, row in comparison_df.iterrows():\n",
    "            print(f\"{row['experiment']:<25} {row['best_model']:<20} {row['rmse']:.0f}      {row['mape']:.4f}\")\n",
    "        \n",
    "        return comparison_df\n",
    "    \n",
    "    def full_pipeline(\n",
    "        self,\n",
    "        start_date: str = \"2023-01-01\",\n",
    "        end_date: str = \"2024-12-31\",\n",
    "        respondent: str = \"US48\",\n",
    "        fueltype: str = \"NG\",\n",
    "        track_with_mlflow: bool = False\n",
    "    ) -> Tuple[pd.DataFrame, Dict]:\n",
    "        \"\"\"\n",
    "        Run the complete pipeline: pull -> prepare -> validate -> stats.\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start date for data pull (YYYY-MM-DD)\n",
    "            end_date: End date for data pull (YYYY-MM-DD)\n",
    "            respondent: Region code (default: US48)\n",
    "            fueltype: Fuel type code (default: NG)\n",
    "            track_with_mlflow: Whether to log to MLflow (default: False)\n",
    "        \n",
    "        Returns:\n",
    "            (cleaned_dataframe, statistics_dict)\n",
    "        \n",
    "        Example:\n",
    "            >>> df, stats = fetcher.full_pipeline()\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting full pipeline: {start_date} to {end_date}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FULL PIPELINE: Pull -> Prepare -> Validate -> Stats\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Start MLflow run if enabled\n",
    "        if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "            mlflow.start_run(run_name=f\"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "            mlflow.log_param(\"start_date\", start_date)\n",
    "            mlflow.log_param(\"end_date\", end_date)\n",
    "            mlflow.log_param(\"respondent\", respondent)\n",
    "            mlflow.log_param(\"fueltype\", fueltype)\n",
    "            logger.info(\"MLflow run started\")\n",
    "        \n",
    "        try:\n",
    "            # Step 2: Pull\n",
    "            logger.info(\"Pulling raw data from EIA API\")\n",
    "            df_raw = self.pull_data(start_date, end_date, respondent, fueltype)\n",
    "            \n",
    "            # Step 3: Inspect\n",
    "            logger.info(f\"Raw data shape: {df_raw.shape}\")\n",
    "            self.inspect_data(df_raw)\n",
    "            \n",
    "            # Step 4: Prepare\n",
    "            logger.info(\"Preparing data\")\n",
    "            df_clean = self.prepare_data(df_raw)\n",
    "            \n",
    "            # Step 5: Validate\n",
    "            logger.info(\"Validating data\")\n",
    "            is_valid = self.validate_data(df_clean)\n",
    "            \n",
    "            if not is_valid:\n",
    "                logger.warning(\"Data validation failed\")\n",
    "                if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                    mlflow.log_param(\"validation_status\", \"failed\")\n",
    "            else:\n",
    "                logger.info(\"Data validation passed\")\n",
    "                if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                    mlflow.log_param(\"validation_status\", \"passed\")\n",
    "            \n",
    "            # Step 6: Stats\n",
    "            logger.info(\"Computing statistics\")\n",
    "            stats = self.get_stats(df_clean)\n",
    "            \n",
    "            # Log stats to MLflow\n",
    "            if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                mlflow.log_metric(\"record_count\", stats['record_count'])\n",
    "                mlflow.log_metric(\"value_min\", stats['value_stats']['min'])\n",
    "                mlflow.log_metric(\"value_max\", stats['value_stats']['max'])\n",
    "                mlflow.log_metric(\"value_mean\", stats['value_stats']['mean'])\n",
    "                mlflow.log_metric(\"missing_count\", stats['missing_count'])\n",
    "                logger.info(\"Statistics logged to MLflow\")\n",
    "            \n",
    "            logger.info(\"Full pipeline completed successfully\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"PIPELINE COMPLETE\")\n",
    "            print(\"=\"*60 + \"\\n\")\n",
    "            \n",
    "            return df_clean, stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Pipeline failed with error: {str(e)}\", exc_info=True)\n",
    "            if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                mlflow.log_param(\"error\", str(e))\n",
    "            raise\n",
    "        \n",
    "        finally:\n",
    "            if track_with_mlflow and MLFLOW_AVAILABLE:\n",
    "                mlflow.end_run()\n",
    "                logger.info(\"MLflow run ended\")\n",
    "\n",
    "\n",
    "# Allow testing individual steps\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = os.getenv(\"EIA_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"Error: EIA_API_KEY not found in environment variables or .env file\")\n",
    "        print(\"Please create a .env file with: EIA_API_KEY=your_api_key_here\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Initialize\n",
    "    fetcher = EIADataFetcher(api_key)\n",
    "    \n",
    "    # Run full pipeline\n",
    "    df, stats = fetcher.full_pipeline(\n",
    "        start_date=\"2024-12-01\",\n",
    "        end_date=\"2024-12-31\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nLast 5 rows:\")\n",
    "    print(df.tail())\n",
    "    \n",
    "    print(\"\\n[OK] Data successfully loaded from .env file!\")\n",
    "    print(\"[OK] Ready for time series analysis and forecasting\")\n",
    "    \n",
    "    # FORECASTING WORKFLOW\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FORECASTING WORKFLOW\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Prepare data for forecasting\n",
    "    df_forecast = fetcher.prepare_for_forecasting(df)\n",
    "    print(f\"\\nData reformatted for forecasting:\")\n",
    "    print(f\"  Columns: {list(df_forecast.columns)}\")\n",
    "    print(f\"  Shape: {df_forecast.shape}\")\n",
    "    \n",
    "    # Step 2: Train/test split (72 hours test set)\n",
    "    train_df, test_df = fetcher.train_test_split(df_forecast, test_hours=72)\n",
    "    \n",
    "    # Step 3: Train models and create forecast\n",
    "    forecast_df = fetcher.forecast(train_df, horizon=len(test_df))\n",
    "    \n",
    "    # Step 4: Evaluate performance (pass train_df for MASE)\n",
    "    metrics = fetcher.evaluate_forecast(forecast_df, test_df, train_df=train_df)\n",
    "    \n",
    "    # Step 5: Visualize results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VISUALIZATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nGenerating forecast visualization...\")\n",
    "        \n",
    "        # Create the plot using StatsForecast's plot method\n",
    "        p = fetcher._create_plot(test_df, forecast_df)\n",
    "        \n",
    "        # Display the plot inline in Jupyter\n",
    "        p.show()\n",
    "        \n",
    "        print(f\"  [OK] Forecast plot displayed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  [INFO] Plotly visualization setup: {str(e)[:60]}...\")\n",
    "        print(\"  (This is optional - forecast metrics are available above)\")\n",
    "    \n",
    "    print(\"\\n[OK] Forecasting workflow complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5994a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atsaf (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
