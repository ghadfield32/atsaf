{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renewable Energy Forecasting Pipeline\n",
    "\n",
    "This notebook walks through building a **next-24h renewable generation forecast system** with:\n",
    "\n",
    "- **EIA data integration** - Hourly wind/solar generation for US regions\n",
    "- **Weather features** - Open-Meteo integration (wind speed, solar radiation)\n",
    "- **Probabilistic forecasting** - Dual prediction intervals (80%, 95%)\n",
    "- **Drift monitoring** - Automatic detection of model degradation\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "EIA API (WND/SUN) ──┐\n",
    "                    ├──► Data Pipeline ──► StatsForecast ──► Predictions\n",
    "Open-Meteo API ─────┘         │                  │              │\n",
    "                              ▼                  ▼              ▼\n",
    "                         Validation        Multi-Series    Probabilistic\n",
    "                         & Quality         [unique_id,     (80%, 95%\n",
    "                                           ds, y, X]       intervals)\n",
    "                                                              │\n",
    "                                                              ▼\n",
    "                                                         Streamlit\n",
    "                                                         Dashboard\n",
    "                                                         (drift, alerts)\n",
    "```\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **StatsForecast format**: `[unique_id, ds, y]` - where `unique_id` = `{region}_{fuel_type}`\n",
    "2. **Zero-value handling**: Solar generates 0 at night - we use RMSE/MAE, NOT MAPE\n",
    "3. **Leakage prevention**: Use **forecasted** weather for predictions, not historical\n",
    "4. **Drift detection**: Threshold = mean + 2*std from backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's ensure we have the project root in our path and configure logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\docker_projects\\atsaf\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Configure logging for visibility\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 1: Region Definitions\n",
    "\n",
    "**File:** `src/renewable/regions.py`\n",
    "\n",
    "This module maps **EIA balancing authority regions** to their geographic coordinates. Why do we need coordinates?\n",
    "\n",
    "- **Weather API lookup**: Open-Meteo requires latitude/longitude\n",
    "- **Regional analysis**: Compare forecast accuracy across regions\n",
    "- **Timezone handling**: Each region has a primary timezone\n",
    "\n",
    "## Key Design Decisions\n",
    "\n",
    "1. **NamedTuple for RegionInfo**: Immutable, type-safe, and memory-efficient\n",
    "2. **Centroid coordinates**: Approximate centers - good enough for hourly weather\n",
    "3. **Fuel type codes**: `WND` (wind), `SUN` (solar) - match EIA's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 1: Region Definitions\n",
    "# This is the foundation - defines WHERE our data comes from\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "class RegionInfo(NamedTuple):\n",
    "    \"\"\"Region metadata for EIA and weather lookups.\"\"\"\n",
    "    name: str\n",
    "    lat: float\n",
    "    lon: float\n",
    "    timezone: str\n",
    "\n",
    "\n",
    "# EIA Balancing Authority regions with centroid coordinates\n",
    "REGIONS: dict[str, RegionInfo] = {\n",
    "    # Western Interconnection\n",
    "    \"CALI\": RegionInfo(name=\"California ISO\", lat=36.7, lon=-119.4, timezone=\"America/Los_Angeles\"),\n",
    "    \"NW\": RegionInfo(name=\"Northwest\", lat=45.5, lon=-122.0, timezone=\"America/Los_Angeles\"),\n",
    "    \"SW\": RegionInfo(name=\"Southwest\", lat=33.5, lon=-112.0, timezone=\"America/Phoenix\"),\n",
    "    \n",
    "    # Texas Interconnection (its own grid!)\n",
    "    \"ERCO\": RegionInfo(name=\"ERCOT (Texas)\", lat=31.0, lon=-100.0, timezone=\"America/Chicago\"),\n",
    "    \n",
    "    # Eastern Interconnection - Northeast\n",
    "    \"NE\": RegionInfo(name=\"New England ISO\", lat=42.3, lon=-71.5, timezone=\"America/New_York\"),\n",
    "    \"NY\": RegionInfo(name=\"New York ISO\", lat=42.5, lon=-75.5, timezone=\"America/New_York\"),\n",
    "    \"PJM\": RegionInfo(name=\"PJM Interconnection\", lat=40.0, lon=-77.0, timezone=\"America/New_York\"),\n",
    "    \n",
    "    # Eastern Interconnection - Midwest\n",
    "    \"MISO\": RegionInfo(name=\"Midcontinent ISO\", lat=41.0, lon=-93.0, timezone=\"America/Chicago\"),\n",
    "    \"SWPP\": RegionInfo(name=\"Southwest Power Pool\", lat=36.0, lon=-97.0, timezone=\"America/Chicago\"),\n",
    "    \"CENT\": RegionInfo(name=\"Central\", lat=39.0, lon=-95.0, timezone=\"America/Chicago\"),\n",
    "    \n",
    "    # Eastern Interconnection - Southeast\n",
    "    \"SE\": RegionInfo(name=\"Southeast\", lat=33.0, lon=-84.0, timezone=\"America/New_York\"),\n",
    "    \"FLA\": RegionInfo(name=\"Florida\", lat=28.0, lon=-82.0, timezone=\"America/New_York\"),\n",
    "    \"CAR\": RegionInfo(name=\"Carolinas\", lat=35.5, lon=-80.0, timezone=\"America/New_York\"),\n",
    "    \"TEN\": RegionInfo(name=\"Tennessee Valley\", lat=35.5, lon=-86.0, timezone=\"America/Chicago\"),\n",
    "    \n",
    "    # Aggregate\n",
    "    \"US48\": RegionInfo(name=\"Lower 48 States\", lat=39.8, lon=-98.5, timezone=\"America/Chicago\"),\n",
    "}\n",
    "\n",
    "# Fuel type codes for renewable generation\n",
    "FUEL_TYPES = {\n",
    "    \"WND\": \"Wind\",\n",
    "    \"SUN\": \"Solar\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_region_coords(region_code: str) -> tuple[float, float]:\n",
    "    \"\"\"Return (lat, lon) for weather API lookup.\"\"\"\n",
    "    region = REGIONS[region_code]\n",
    "    return (region.lat, region.lon)\n",
    "\n",
    "\n",
    "def list_regions() -> list[str]:\n",
    "    \"\"\"Return all valid region codes.\"\"\"\n",
    "    return sorted(REGIONS.keys())\n",
    "\n",
    "\n",
    "def get_region_info(region_code: str) -> RegionInfo:\n",
    "    \"\"\"Get full region information.\"\"\"\n",
    "    return REGIONS[region_code]\n",
    "\n",
    "\n",
    "def validate_region(region_code: str) -> bool:\n",
    "    \"\"\"Check if region code is valid.\"\"\"\n",
    "    return region_code in REGIONS\n",
    "\n",
    "\n",
    "def validate_fuel_type(fuel_type: str) -> bool:\n",
    "    \"\"\"Check if fuel type code is valid.\"\"\"\n",
    "    return fuel_type in FUEL_TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Using Region Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Available Regions ===\n",
      "Total regions: 15\n",
      "Region codes: ['CALI', 'CAR', 'CENT', 'ERCO', 'FLA', 'MISO', 'NE', 'NW', 'NY', 'PJM', 'SE', 'SW', 'SWPP', 'TEN', 'US48']\n",
      "\n",
      "=== Example: California ===\n",
      "Name: California ISO\n",
      "Coordinates: (36.7, -119.4)\n",
      "Timezone: America/Los_Angeles\n",
      "\n",
      "=== Weather API Coordinates ===\n",
      "CALI: lat=36.7, lon=-119.4\n",
      "ERCO: lat=31.0, lon=-100.0\n",
      "MISO: lat=41.0, lon=-93.0\n",
      "\n",
      "=== Fuel Types ===\n",
      "WND: Wind\n",
      "SUN: Solar\n",
      "\n",
      "=== Validation ===\n",
      "validate_region('CALI'): True\n",
      "validate_region('INVALID'): False\n",
      "validate_fuel_type('WND'): True\n"
     ]
    }
   ],
   "source": [
    "# Example run - test region functions\n",
    "\n",
    "print(\"=== Available Regions ===\")\n",
    "print(f\"Total regions: {len(REGIONS)}\")\n",
    "print(f\"Region codes: {list_regions()}\")\n",
    "\n",
    "print(\"\\n=== Example: California ===\")\n",
    "cali_info = get_region_info(\"CALI\")\n",
    "print(f\"Name: {cali_info.name}\")\n",
    "print(f\"Coordinates: ({cali_info.lat}, {cali_info.lon})\")\n",
    "print(f\"Timezone: {cali_info.timezone}\")\n",
    "\n",
    "print(\"\\n=== Weather API Coordinates ===\")\n",
    "for region in [\"CALI\", \"ERCO\", \"MISO\"]:\n",
    "    lat, lon = get_region_coords(region)\n",
    "    print(f\"{region}: lat={lat}, lon={lon}\")\n",
    "\n",
    "print(\"\\n=== Fuel Types ===\")\n",
    "for code, name in FUEL_TYPES.items():\n",
    "    print(f\"{code}: {name}\")\n",
    "\n",
    "print(\"\\n=== Validation ===\")\n",
    "print(f\"validate_region('CALI'): {validate_region('CALI')}\")\n",
    "print(f\"validate_region('INVALID'): {validate_region('INVALID')}\")\n",
    "print(f\"validate_fuel_type('WND'): {validate_fuel_type('WND')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 2: EIA Data Fetcher\n",
    "\n",
    "**File:** `src/renewable/eia_renewable.py`\n",
    "\n",
    "This module fetches **hourly wind and solar generation** from the EIA API.\n",
    "\n",
    "## Critical Concepts\n",
    "\n",
    "### StatsForecast Format\n",
    "StatsForecast expects data in a specific format:\n",
    "```\n",
    "unique_id | ds                  | y\n",
    "----------|---------------------|--------\n",
    "CALI_WND  | 2024-01-01 00:00:00 | 1234.5\n",
    "CALI_WND  | 2024-01-01 01:00:00 | 1456.7\n",
    "ERCO_WND  | 2024-01-01 00:00:00 | 2345.6\n",
    "```\n",
    "\n",
    "- `unique_id`: Identifies the time series (e.g., \"CALI_WND\" = California Wind)\n",
    "- `ds`: Datetime column (timezone-naive UTC)\n",
    "- `y`: Target value (generation in MWh)\n",
    "\n",
    "### API Rate Limiting\n",
    "- EIA API has rate limits (~5 requests/second)\n",
    "- We use controlled parallelism with delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 2: EIA Data Fetcher\n",
    "# Fetches wind/solar generation data for multi-series forecasting\n",
    "\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class EIARenewableFetcher:\n",
    "    \"\"\"Fetch wind/solar data for multiple regions from EIA API.\n",
    "    \n",
    "    Outputs data in StatsForecast multi-series format:\n",
    "    - unique_id: \"{region}_{fuel_type}\" (e.g., \"CALI_WND\")\n",
    "    - ds: timezone-naive UTC datetime\n",
    "    - y: generation value (MWh)\n",
    "    \"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.eia.gov/v2/electricity/rto/fuel-type-data/data/\"\n",
    "    MAX_RECORDS_PER_REQUEST = 5000\n",
    "    RATE_LIMIT_DELAY = 0.2  # 5 requests/second max\n",
    "    \n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        \"\"\"Initialize with EIA API key.\"\"\"\n",
    "        self.api_key = api_key or os.getenv(\"EIA_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\n",
    "                \"EIA API key required. Set EIA_API_KEY environment variable \"\n",
    "                \"or pass api_key parameter.\"\n",
    "            )\n",
    "    \n",
    "    def fetch_region(\n",
    "        self,\n",
    "        region: str,\n",
    "        fuel_type: str,\n",
    "        start_date: str,\n",
    "        end_date: str,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Fetch data for a single region and fuel type.\"\"\"\n",
    "        if not validate_region(region):\n",
    "            raise ValueError(f\"Invalid region: {region}\")\n",
    "        if not validate_fuel_type(fuel_type):\n",
    "            raise ValueError(f\"Invalid fuel type: {fuel_type}\")\n",
    "        \n",
    "        all_records = []\n",
    "        offset = 0\n",
    "        \n",
    "        while True:\n",
    "            params = {\n",
    "                \"api_key\": self.api_key,\n",
    "                \"data[]\": \"value\",\n",
    "                \"facets[respondent][]\": region,\n",
    "                \"facets[fueltype][]\": fuel_type,\n",
    "                \"frequency\": \"hourly\",\n",
    "                \"start\": f\"{start_date}T00\",\n",
    "                \"end\": f\"{end_date}T23\",\n",
    "                \"length\": self.MAX_RECORDS_PER_REQUEST,\n",
    "                \"offset\": offset,\n",
    "                \"sort[0][column]\": \"period\",\n",
    "                \"sort[0][direction]\": \"asc\",\n",
    "            }\n",
    "            \n",
    "            response = requests.get(self.BASE_URL, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            if \"response\" not in data or \"data\" not in data[\"response\"]:\n",
    "                break\n",
    "            \n",
    "            records = data[\"response\"][\"data\"]\n",
    "            if not records:\n",
    "                break\n",
    "            \n",
    "            all_records.extend(records)\n",
    "            offset += self.MAX_RECORDS_PER_REQUEST\n",
    "            time.sleep(self.RATE_LIMIT_DELAY)\n",
    "        \n",
    "        if not all_records:\n",
    "            return pd.DataFrame(columns=[\"ds\", \"value\", \"region\", \"fuel_type\"])\n",
    "        \n",
    "        df = pd.DataFrame(all_records)\n",
    "        df[\"ds\"] = pd.to_datetime(df[\"period\"], errors=\"coerce\")\n",
    "        df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "        df[\"region\"] = region\n",
    "        df[\"fuel_type\"] = fuel_type\n",
    "        df = df.dropna(subset=[\"ds\", \"value\"])\n",
    "        \n",
    "        # Convert to UTC naive\n",
    "        if df[\"ds\"].dt.tz is not None:\n",
    "            df[\"ds\"] = df[\"ds\"].dt.tz_convert(\"UTC\").dt.tz_localize(None)\n",
    "        \n",
    "        return df[[\"ds\", \"value\", \"region\", \"fuel_type\"]].sort_values(\"ds\").reset_index(drop=True)\n",
    "    \n",
    "    def fetch_all_regions(\n",
    "        self,\n",
    "        fuel_type: str,\n",
    "        start_date: str,\n",
    "        end_date: str,\n",
    "        regions: Optional[list[str]] = None,\n",
    "        max_workers: int = 3,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Fetch data for all regions, return in StatsForecast format.\n",
    "        \n",
    "        Returns DataFrame with columns [unique_id, ds, y]\n",
    "        where unique_id = \"{region}_{fuel_type}\" (e.g., \"CALI_WND\")\n",
    "        \"\"\"\n",
    "        if regions is None:\n",
    "            regions = [r for r in REGIONS.keys() if r != \"US48\"]\n",
    "        \n",
    "        all_dfs = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {\n",
    "                executor.submit(\n",
    "                    self.fetch_region, region, fuel_type, start_date, end_date\n",
    "                ): region\n",
    "                for region in regions\n",
    "            }\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                region = futures[future]\n",
    "                try:\n",
    "                    df = future.result()\n",
    "                    if len(df) > 0:\n",
    "                        all_dfs.append(df)\n",
    "                        print(f\"[OK] {region}: {len(df)} rows\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[FAIL] {region}: {e}\")\n",
    "        \n",
    "        if not all_dfs:\n",
    "            return pd.DataFrame(columns=[\"unique_id\", \"ds\", \"y\"])\n",
    "        \n",
    "        combined = pd.concat(all_dfs, ignore_index=True)\n",
    "        \n",
    "        # Create unique_id for StatsForecast format\n",
    "        combined[\"unique_id\"] = combined[\"region\"] + \"_\" + combined[\"fuel_type\"]\n",
    "        combined = combined.rename(columns={\"value\": \"y\"})\n",
    "        \n",
    "        return combined[[\"unique_id\", \"ds\", \"y\"]].sort_values([\"unique_id\", \"ds\"]).reset_index(drop=True)\n",
    "    \n",
    "    def get_series_summary(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Get summary statistics per series.\"\"\"\n",
    "        return df.groupby(\"unique_id\").agg(\n",
    "            count=(\"y\", \"count\"),\n",
    "            min_value=(\"y\", \"min\"),\n",
    "            max_value=(\"y\", \"max\"),\n",
    "            mean_value=(\"y\", \"mean\"),\n",
    "            zero_count=(\"y\", lambda x: (x == 0).sum()),\n",
    "        ).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Fetching EIA Data\n",
    "\n",
    "**Note:** This requires a valid EIA API key. Get one free at: https://www.eia.gov/opendata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Single Region Fetch ===\n",
      "Single region: 0 rows\n",
      "Empty DataFrame\n",
      "Columns: [ds, value, region, fuel_type]\n",
      "Index: []\n",
      "\n",
      "=== Testing Multi-Region Fetch ===\n",
      "[OK] ERCO: 49 rows\n",
      "[OK] MISO: 49 rows\n",
      "\n",
      "Multi-region: 98 rows\n",
      "Series: ['ERCO_WND', 'MISO_WND']\n",
      "\n",
      "=== Series Summary ===\n",
      "  unique_id  count  min_value  max_value   mean_value  zero_count\n",
      "0  ERCO_WND     49        747       9331  4775.061224           0\n",
      "1  MISO_WND     49       4648      11717  8110.673469           0\n"
     ]
    }
   ],
   "source": [
    "# Example run - test EIA fetcher\n",
    "# Requires EIA_API_KEY environment variable\n",
    "\n",
    "try:\n",
    "    fetcher = EIARenewableFetcher()\n",
    "    \n",
    "    print(\"=== Testing Single Region Fetch ===\")\n",
    "    df_single = fetcher.fetch_region(\n",
    "        region=\"CALI\",\n",
    "        fuel_type=\"WND\",\n",
    "        start_date=\"2024-12-01\",\n",
    "        end_date=\"2024-12-03\",\n",
    "    )\n",
    "    print(f\"Single region: {len(df_single)} rows\")\n",
    "    print(df_single.head())\n",
    "    \n",
    "    print(\"\\n=== Testing Multi-Region Fetch ===\")\n",
    "    df_multi = fetcher.fetch_all_regions(\n",
    "        fuel_type=\"WND\",\n",
    "        start_date=\"2024-12-01\",\n",
    "        end_date=\"2024-12-03\",\n",
    "        regions=[\"CALI\", \"ERCO\", \"MISO\"],\n",
    "    )\n",
    "    print(f\"\\nMulti-region: {len(df_multi)} rows\")\n",
    "    print(f\"Series: {df_multi['unique_id'].unique().tolist()}\")\n",
    "    \n",
    "    print(\"\\n=== Series Summary ===\")\n",
    "    print(fetcher.get_series_summary(df_multi))\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"\\nNote: {e}\")\n",
    "    print(\"Set your EIA API key to run this example.\")\n",
    "    print(\"Get a free key at: https://www.eia.gov/opendata/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 3: Weather Integration\n",
    "\n",
    "**File:** `src/renewable/open_meteo.py`\n",
    "\n",
    "Weather is **critical** for renewable forecasting:\n",
    "- **Wind generation** depends on wind speed (especially at hub height ~100m)\n",
    "- **Solar generation** depends on radiation and cloud cover\n",
    "\n",
    "## Key Concept: Preventing Leakage\n",
    "\n",
    "**Data leakage** occurs when training uses information that wouldn't be available at prediction time.\n",
    "\n",
    "```\n",
    "❌ WRONG: Using historical weather to predict future generation\n",
    "   - At prediction time, we don't have future actual weather!\n",
    "   \n",
    "✅ CORRECT: Use forecasted weather for predictions\n",
    "   - Training: historical weather aligned with historical generation\n",
    "   - Prediction: weather forecast for the prediction horizon\n",
    "```\n",
    "\n",
    "## Open-Meteo API\n",
    "\n",
    "Open-Meteo is **free** and requires no API key:\n",
    "- Historical API: Past weather data\n",
    "- Forecast API: Up to 16 days ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 3: Weather Integration\n",
    "# Fetches weather features from Open-Meteo (free, no API key needed)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "\n",
    "class OpenMeteoRenewable:\n",
    "    \"\"\"Fetch weather features for renewable energy forecasting.\n",
    "    \n",
    "    Uses Open-Meteo APIs (free, no API key required):\n",
    "    - Historical: archive-api.open-meteo.com (past data)\n",
    "    - Forecast: api.open-meteo.com (up to 16 days ahead)\n",
    "    \"\"\"\n",
    "    \n",
    "    HISTORICAL_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    FORECAST_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Weather variables relevant for renewable forecasting\n",
    "    WEATHER_VARS = [\n",
    "        \"temperature_2m\",      # Ambient temperature\n",
    "        \"wind_speed_10m\",      # Wind at 10m (standard measurement height)\n",
    "        \"wind_speed_100m\",     # Wind at hub height (~100m for turbines)\n",
    "        \"wind_direction_10m\",  # Wind direction\n",
    "        \"direct_radiation\",    # Direct solar radiation\n",
    "        \"diffuse_radiation\",   # Diffuse solar radiation\n",
    "        \"cloud_cover\",         # Cloud coverage (%)\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, timeout: int = 30):\n",
    "        self.timeout = timeout\n",
    "        self.session = self._create_session()\n",
    "    \n",
    "    def _create_session(self) -> requests.Session:\n",
    "        \"\"\"Create session with retry logic.\"\"\"\n",
    "        session = requests.Session()\n",
    "        retries = Retry(total=3, backoff_factor=0.5, status_forcelist=[500, 502, 503, 504])\n",
    "        session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "        return session\n",
    "    \n",
    "    def fetch_historical(\n",
    "        self,\n",
    "        lat: float,\n",
    "        lon: float,\n",
    "        start_date: str,\n",
    "        end_date: str,\n",
    "        variables: Optional[list[str]] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Fetch historical hourly weather data.\n",
    "        \n",
    "        Use this for TRAINING data to align with historical generation.\n",
    "        \"\"\"\n",
    "        if variables is None:\n",
    "            variables = self.WEATHER_VARS\n",
    "        \n",
    "        params = {\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"hourly\": \",\".join(variables),\n",
    "            \"timezone\": \"UTC\",\n",
    "        }\n",
    "        \n",
    "        response = self.session.get(self.HISTORICAL_URL, params=params, timeout=self.timeout)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        return self._parse_response(response.json(), variables)\n",
    "    \n",
    "    def fetch_forecast(\n",
    "        self,\n",
    "        lat: float,\n",
    "        lon: float,\n",
    "        horizon_hours: int = 48,\n",
    "        variables: Optional[list[str]] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Fetch weather forecast for future predictions.\n",
    "        \n",
    "        CRITICAL: Use this for PREDICTION features to avoid leakage!\n",
    "        Do NOT use historical weather for future forecasts.\n",
    "        \"\"\"\n",
    "        if variables is None:\n",
    "            variables = self.WEATHER_VARS\n",
    "        \n",
    "        forecast_days = min((horizon_hours // 24) + 1, 16)\n",
    "        \n",
    "        params = {\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"hourly\": \",\".join(variables),\n",
    "            \"timezone\": \"UTC\",\n",
    "            \"forecast_days\": forecast_days,\n",
    "        }\n",
    "        \n",
    "        response = self.session.get(self.FORECAST_URL, params=params, timeout=self.timeout)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        df = self._parse_response(response.json(), variables)\n",
    "        \n",
    "        # Trim to requested horizon\n",
    "        if len(df) > 0:\n",
    "            cutoff = datetime.utcnow() + timedelta(hours=horizon_hours)\n",
    "            df = df[df[\"ds\"] <= cutoff].reset_index(drop=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def fetch_for_region(\n",
    "        self,\n",
    "        region_code: str,\n",
    "        start_date: str,\n",
    "        end_date: str,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Fetch historical weather using region centroid coordinates.\"\"\"\n",
    "        lat, lon = get_region_coords(region_code)\n",
    "        df = self.fetch_historical(lat, lon, start_date, end_date)\n",
    "        df[\"region\"] = region_code\n",
    "        return df\n",
    "    \n",
    "    def fetch_all_regions_historical(\n",
    "        self,\n",
    "        regions: list[str],\n",
    "        start_date: str,\n",
    "        end_date: str,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Fetch historical weather for multiple regions.\"\"\"\n",
    "        all_dfs = []\n",
    "        \n",
    "        for region in regions:\n",
    "            try:\n",
    "                df = self.fetch_for_region(region, start_date, end_date)\n",
    "                all_dfs.append(df)\n",
    "                print(f\"[OK] Weather for {region}: {len(df)} rows\")\n",
    "            except Exception as e:\n",
    "                print(f\"[FAIL] Weather for {region}: {e}\")\n",
    "        \n",
    "        if not all_dfs:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        return pd.concat(all_dfs, ignore_index=True).sort_values([\"region\", \"ds\"]).reset_index(drop=True)\n",
    "    \n",
    "    def _parse_response(self, data: dict, variables: list[str]) -> pd.DataFrame:\n",
    "        \"\"\"Parse Open-Meteo API response to DataFrame.\"\"\"\n",
    "        hourly = data.get(\"hourly\", {})\n",
    "        times = hourly.get(\"time\", [])\n",
    "        \n",
    "        if not times:\n",
    "            return pd.DataFrame(columns=[\"ds\"] + variables)\n",
    "        \n",
    "        df_data = {\"ds\": pd.to_datetime(times, errors=\"coerce\", utc=True).tz_localize(None)}\n",
    "        \n",
    "        for var in variables:\n",
    "            values = hourly.get(var)\n",
    "            df_data[var] = values if values else [None] * len(times)\n",
    "        \n",
    "        df = pd.DataFrame(df_data)\n",
    "        \n",
    "        for var in variables:\n",
    "            if var in df.columns:\n",
    "                df[var] = pd.to_numeric(df[var], errors=\"coerce\")\n",
    "        \n",
    "        return df.sort_values(\"ds\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Fetching Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Historical Weather ===\n",
      "Historical: 72 rows\n",
      "                   ds  temperature_2m  wind_speed_10m  wind_speed_100m  \\\n",
      "0 2024-12-01 00:00:00            12.2             5.9              7.0   \n",
      "1 2024-12-01 01:00:00             9.2             1.2              5.3   \n",
      "2 2024-12-01 02:00:00             8.4             2.4              3.6   \n",
      "3 2024-12-01 03:00:00             8.7             3.8              5.4   \n",
      "4 2024-12-01 04:00:00            10.3             0.9              2.2   \n",
      "\n",
      "   wind_direction_10m  direct_radiation  diffuse_radiation  cloud_cover region  \n",
      "0                  72              84.0               57.0          100   CALI  \n",
      "1                  27               6.0               12.0           41   CALI  \n",
      "2                  63               0.0                0.0          100   CALI  \n",
      "3                  90               0.0                0.0          100   CALI  \n",
      "4                 101               0.0                0.0          100   CALI  \n",
      "\n",
      "=== Testing Weather Forecast ===\n",
      "Forecast: 45 rows\n",
      "                   ds  temperature_2m  wind_speed_10m  wind_speed_100m  \\\n",
      "0 2026-01-13 00:00:00            14.3             5.4              5.8   \n",
      "1 2026-01-13 01:00:00            12.7             3.1              4.9   \n",
      "2 2026-01-13 02:00:00            11.0             4.5              2.7   \n",
      "3 2026-01-13 03:00:00             9.8             8.1              3.9   \n",
      "4 2026-01-13 04:00:00             9.4             8.0              6.5   \n",
      "\n",
      "   wind_direction_10m  direct_radiation  diffuse_radiation  cloud_cover  \n",
      "0                 266             174.8               58.2            0  \n",
      "1                 291              37.8               25.2            0  \n",
      "2                  29               0.0                0.0            0  \n",
      "3                  32               0.0                0.0            0  \n",
      "4                  10               0.0                0.0            0  \n",
      "\n",
      "=== Weather Variables Explained ===\n",
      "Wind forecasting:\n",
      "  - wind_speed_10m: Standard measurement height\n",
      "  - wind_speed_100m: Hub height for wind turbines (critical!)\n",
      "\n",
      "Solar forecasting:\n",
      "  - direct_radiation: Direct sunlight (W/m²)\n",
      "  - diffuse_radiation: Scattered light from clouds\n",
      "  - cloud_cover: Affects both direct and diffuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_124040\\2312918783.py:103: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  cutoff = datetime.utcnow() + timedelta(hours=horizon_hours)\n"
     ]
    }
   ],
   "source": [
    "# Example run - test weather fetcher (no API key needed!)\n",
    "\n",
    "weather = OpenMeteoRenewable()\n",
    "\n",
    "print(\"=== Testing Historical Weather ===\")\n",
    "hist_df = weather.fetch_for_region(\n",
    "    region_code=\"CALI\",\n",
    "    start_date=\"2024-12-01\",\n",
    "    end_date=\"2024-12-03\",\n",
    ")\n",
    "print(f\"Historical: {len(hist_df)} rows\")\n",
    "print(hist_df.head())\n",
    "\n",
    "print(\"\\n=== Testing Weather Forecast ===\")\n",
    "fcst_df = weather.fetch_forecast(\n",
    "    lat=36.7, lon=-119.4,\n",
    "    horizon_hours=24,\n",
    ")\n",
    "print(f\"Forecast: {len(fcst_df)} rows\")\n",
    "print(fcst_df.head())\n",
    "\n",
    "print(\"\\n=== Weather Variables Explained ===\")\n",
    "print(\"Wind forecasting:\")\n",
    "print(\"  - wind_speed_10m: Standard measurement height\")\n",
    "print(\"  - wind_speed_100m: Hub height for wind turbines (critical!)\")\n",
    "print(\"\\nSolar forecasting:\")\n",
    "print(\"  - direct_radiation: Direct sunlight (W/m²)\")\n",
    "print(\"  - diffuse_radiation: Scattered light from clouds\")\n",
    "print(\"  - cloud_cover: Affects both direct and diffuse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 4: Probabilistic Modeling\n",
    "\n",
    "**File:** `src/renewable/modeling.py`\n",
    "\n",
    "This is where the forecasting happens! We use **StatsForecast** for:\n",
    "\n",
    "1. **Multi-series forecasting**: Handle multiple regions/fuel types in one model\n",
    "2. **Probabilistic predictions**: Get prediction intervals, not just point forecasts\n",
    "3. **Weather exogenous**: Include weather features as predictors\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Why Prediction Intervals?\n",
    "\n",
    "Point forecasts are useful, but energy traders need **uncertainty quantification**:\n",
    "- **80% interval**: \"I'm 80% confident generation will be between X and Y\"\n",
    "- **95% interval**: Wider, for risk management\n",
    "\n",
    "### Zero-Value Safety (CRITICAL)\n",
    "\n",
    "**Solar panels generate ZERO at night!** This breaks MAPE:\n",
    "\n",
    "```\n",
    "MAPE = mean(|actual - predicted| / actual)\n",
    "\n",
    "When actual = 0:\n",
    "MAPE = |0 - pred| / 0 = undefined (division by zero!)\n",
    "```\n",
    "\n",
    "**Solution**: Always use RMSE and MAE for renewable forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 4: Probabilistic Modeling\n",
    "# Multi-series forecasting with prediction intervals\n",
    "\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Import our evaluation metrics (from chapter 2)\n",
    "from src.chapter2.evaluation import ForecastMetrics\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ForecastConfig:\n",
    "    \"\"\"Configuration for renewable forecasting.\"\"\"\n",
    "    horizon: int = 24\n",
    "    confidence_levels: tuple[int, int] = (80, 95)\n",
    "    season_length: int = 24  # Hourly seasonality\n",
    "    weekly_season: int = 168  # 24 * 7\n",
    "    models: list[str] = field(default_factory=lambda: [\"AutoARIMA\", \"MSTL\"])\n",
    "\n",
    "\n",
    "class RenewableForecastModel:\n",
    "    \"\"\"Multi-series probabilistic forecasting with weather exogenous.\n",
    "    \n",
    "    Designed for wind/solar generation with:\n",
    "    - Weather features (wind speed, solar radiation)\n",
    "    - Dual prediction intervals (80%, 95%)\n",
    "    - Zero-safe metrics (solar has 0s at night)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        horizon: int = 24,\n",
    "        confidence_levels: tuple[int, int] = (80, 95),\n",
    "    ):\n",
    "        self.horizon = horizon\n",
    "        self.confidence_levels = confidence_levels\n",
    "        self.sf = None\n",
    "        self.fitted = False\n",
    "    \n",
    "    def prepare_features(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        weather_df: Optional[pd.DataFrame] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Add time and weather features.\n",
    "        \n",
    "        Time features use cyclic encoding (sin/cos) because:\n",
    "        - Hour 23 and Hour 0 are adjacent, but 23 > 0 numerically\n",
    "        - Sin/cos creates a smooth circular representation\n",
    "        \"\"\"\n",
    "        result = df.copy()\n",
    "        \n",
    "        # Cyclic encoding for hour of day\n",
    "        result[\"hour\"] = result[\"ds\"].dt.hour\n",
    "        result[\"hour_sin\"] = np.sin(2 * np.pi * result[\"hour\"] / 24)\n",
    "        result[\"hour_cos\"] = np.cos(2 * np.pi * result[\"hour\"] / 24)\n",
    "        \n",
    "        # Cyclic encoding for day of week\n",
    "        result[\"dayofweek\"] = result[\"ds\"].dt.dayofweek\n",
    "        result[\"dow_sin\"] = np.sin(2 * np.pi * result[\"dayofweek\"] / 7)\n",
    "        result[\"dow_cos\"] = np.cos(2 * np.pi * result[\"dayofweek\"] / 7)\n",
    "        \n",
    "        # Merge weather if provided\n",
    "        if weather_df is not None and len(weather_df) > 0:\n",
    "            result[\"region\"] = result[\"unique_id\"].str.split(\"_\").str[0]\n",
    "            weather_cols = [c for c in weather_df.columns if c not in [\"ds\", \"region\"]]\n",
    "            \n",
    "            result = result.merge(\n",
    "                weather_df[[\"ds\", \"region\"] + weather_cols],\n",
    "                on=[\"ds\", \"region\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "            \n",
    "            # Forward fill missing weather\n",
    "            for col in weather_cols:\n",
    "                if col in result.columns:\n",
    "                    result[col] = result.groupby(\"unique_id\")[col].ffill()\n",
    "            \n",
    "            result = result.drop(columns=[\"region\"])\n",
    "        \n",
    "        # Lag features (shifted to prevent leakage)\n",
    "        result = result.sort_values([\"unique_id\", \"ds\"])\n",
    "        result[\"y_lag_1\"] = result.groupby(\"unique_id\")[\"y\"].shift(1)\n",
    "        result[\"y_lag_24\"] = result.groupby(\"unique_id\")[\"y\"].shift(24)\n",
    "        \n",
    "        result = result.drop(columns=[\"hour\", \"dayofweek\"], errors=\"ignore\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def fit(self, df: pd.DataFrame, weather_df: Optional[pd.DataFrame] = None) -> None:\n",
    "        \"\"\"Train StatsForecast models.\"\"\"\n",
    "        from statsforecast import StatsForecast\n",
    "        from statsforecast.models import MSTL, AutoARIMA, AutoETS, SeasonalNaive\n",
    "        \n",
    "        train_df = self.prepare_features(df, weather_df)\n",
    "        \n",
    "        # Define models\n",
    "        models = [\n",
    "            AutoARIMA(season_length=24),\n",
    "            SeasonalNaive(season_length=24),\n",
    "            AutoETS(season_length=24),\n",
    "            MSTL(\n",
    "                season_length=[24, 168],  # Daily and weekly seasonality\n",
    "                trend_forecaster=AutoARIMA(),\n",
    "                alias=\"MSTL_ARIMA\",\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        self.sf = StatsForecast(models=models, freq=\"h\", n_jobs=-1)\n",
    "        self._train_df = train_df[[\"unique_id\", \"ds\", \"y\"]].copy()\n",
    "        \n",
    "        print(f\"Model fit: {len(train_df)} rows, {train_df['unique_id'].nunique()} series\")\n",
    "        self.fitted = True\n",
    "    \n",
    "    def predict(self, future_weather: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n",
    "        \"\"\"Generate forecasts with dual prediction intervals.\"\"\"\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"Model must be fitted before prediction. Call fit() first.\")\n",
    "        \n",
    "        forecasts = self.sf.forecast(\n",
    "            h=self.horizon,\n",
    "            df=self._train_df,\n",
    "            level=list(self.confidence_levels),\n",
    "        )\n",
    "        \n",
    "        forecasts = forecasts.reset_index()\n",
    "        result = self._standardize_forecast_columns(forecasts)\n",
    "        \n",
    "        print(f\"Predictions generated: {len(result)} rows, {self.horizon}h horizon\")\n",
    "        return result\n",
    "    \n",
    "    def cross_validate(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        weather_df: Optional[pd.DataFrame] = None,\n",
    "        n_windows: int = 5,\n",
    "        step_size: int = 168,\n",
    "    ) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Run rolling-origin cross-validation.\"\"\"\n",
    "        from statsforecast import StatsForecast\n",
    "        from statsforecast.models import MSTL, AutoARIMA, AutoETS, SeasonalNaive\n",
    "        \n",
    "        cv_df = self.prepare_features(df, weather_df)\n",
    "        cv_df = cv_df[[\"unique_id\", \"ds\", \"y\"]].copy()\n",
    "        \n",
    "        models = [\n",
    "            AutoARIMA(season_length=24),\n",
    "            SeasonalNaive(season_length=24),\n",
    "            AutoETS(season_length=24),\n",
    "            MSTL(season_length=[24, 168], trend_forecaster=AutoARIMA(), alias=\"MSTL_ARIMA\"),\n",
    "        ]\n",
    "        \n",
    "        sf = StatsForecast(models=models, freq=\"h\", n_jobs=-1)\n",
    "        \n",
    "        print(f\"Running CV: {n_windows} windows, step={step_size}h, horizon={self.horizon}h\")\n",
    "        \n",
    "        cv_results = sf.cross_validation(\n",
    "            df=cv_df,\n",
    "            h=self.horizon,\n",
    "            step_size=step_size,\n",
    "            n_windows=n_windows,\n",
    "            level=list(self.confidence_levels),\n",
    "        )\n",
    "        \n",
    "        cv_results = cv_results.reset_index()\n",
    "        leaderboard = self._compute_leaderboard(cv_results)\n",
    "        \n",
    "        return cv_results, leaderboard\n",
    "    \n",
    "    def _standardize_forecast_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Standardize column names to yhat, yhat_lo_80, etc.\"\"\"\n",
    "        result = df.copy()\n",
    "        \n",
    "        model_cols = [c for c in result.columns if c not in [\"unique_id\", \"ds\", \"cutoff\"]]\n",
    "        point_cols = [c for c in model_cols if not any(x in c for x in [\"-lo-\", \"-hi-\"])]\n",
    "        \n",
    "        # Prefer MSTL_ARIMA as the main model\n",
    "        if \"MSTL_ARIMA\" in point_cols:\n",
    "            best_model = \"MSTL_ARIMA\"\n",
    "        elif \"AutoARIMA\" in point_cols:\n",
    "            best_model = \"AutoARIMA\"\n",
    "        else:\n",
    "            best_model = point_cols[0] if point_cols else None\n",
    "        \n",
    "        if best_model:\n",
    "            result[\"yhat\"] = result[best_model]\n",
    "            \n",
    "            for level in self.confidence_levels:\n",
    "                lo_col = f\"{best_model}-lo-{level}\"\n",
    "                hi_col = f\"{best_model}-hi-{level}\"\n",
    "                \n",
    "                if lo_col in result.columns:\n",
    "                    result[f\"yhat_lo_{level}\"] = result[lo_col]\n",
    "                if hi_col in result.columns:\n",
    "                    result[f\"yhat_hi_{level}\"] = result[hi_col]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _compute_leaderboard(self, cv_results: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Compute model leaderboard from CV results.\"\"\"\n",
    "        model_cols = [\n",
    "            c for c in cv_results.columns\n",
    "            if c not in [\"unique_id\", \"ds\", \"cutoff\", \"y\"]\n",
    "            and not any(x in c for x in [\"-lo-\", \"-hi-\"])\n",
    "        ]\n",
    "        \n",
    "        rows = []\n",
    "        for model in model_cols:\n",
    "            y_true = cv_results[\"y\"].values\n",
    "            y_pred = cv_results[model].values\n",
    "            \n",
    "            # CRITICAL: Use RMSE and MAE, NOT MAPE (solar has zeros)\n",
    "            rmse = ForecastMetrics.rmse(y_true, y_pred)\n",
    "            mae = ForecastMetrics.mae(y_true, y_pred)\n",
    "            \n",
    "            # Coverage for each level\n",
    "            coverages = {}\n",
    "            for level in self.confidence_levels:\n",
    "                lo_col = f\"{model}-lo-{level}\"\n",
    "                hi_col = f\"{model}-hi-{level}\"\n",
    "                \n",
    "                if lo_col in cv_results.columns and hi_col in cv_results.columns:\n",
    "                    coverage = ForecastMetrics.coverage(\n",
    "                        y_true,\n",
    "                        cv_results[lo_col].values,\n",
    "                        cv_results[hi_col].values,\n",
    "                    )\n",
    "                    coverages[f\"coverage_{level}\"] = coverage\n",
    "            \n",
    "            rows.append({\"model\": model, \"rmse\": rmse, \"mae\": mae, **coverages})\n",
    "        \n",
    "        return pd.DataFrame(rows).sort_values(\"rmse\")\n",
    "    \n",
    "    def compute_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "        \"\"\"Compute metrics - RMSE and MAE only (no MAPE for solar!).\"\"\"\n",
    "        return {\n",
    "            \"rmse\": ForecastMetrics.rmse(y_true, y_pred),\n",
    "            \"mae\": ForecastMetrics.mae(y_true, y_pred),\n",
    "            # NOTE: MAPE intentionally excluded - undefined when y=0\n",
    "        }\n",
    "\n",
    "\n",
    "def compute_baseline_metrics(\n",
    "    cv_results: pd.DataFrame,\n",
    "    model_name: str = \"MSTL_ARIMA\",\n",
    ") -> dict:\n",
    "    \"\"\"Compute baseline metrics from backtest for drift detection.\n",
    "    \n",
    "    Drift threshold = mean + 2*std (flags unusual performance)\n",
    "    \"\"\"\n",
    "    if model_name not in cv_results.columns:\n",
    "        raise ValueError(f\"Model {model_name} not found in CV results\")\n",
    "    \n",
    "    window_metrics = []\n",
    "    for cutoff in cv_results[\"cutoff\"].unique():\n",
    "        window = cv_results[cv_results[\"cutoff\"] == cutoff]\n",
    "        y_true = window[\"y\"].values\n",
    "        y_pred = window[model_name].values\n",
    "        \n",
    "        rmse = ForecastMetrics.rmse(y_true, y_pred)\n",
    "        mae = ForecastMetrics.mae(y_true, y_pred)\n",
    "        window_metrics.append({\"cutoff\": cutoff, \"rmse\": rmse, \"mae\": mae})\n",
    "    \n",
    "    metrics_df = pd.DataFrame(window_metrics)\n",
    "    \n",
    "    baseline = {\n",
    "        \"model\": model_name,\n",
    "        \"rmse_mean\": metrics_df[\"rmse\"].mean(),\n",
    "        \"rmse_std\": metrics_df[\"rmse\"].std(),\n",
    "        \"mae_mean\": metrics_df[\"mae\"].mean(),\n",
    "        \"mae_std\": metrics_df[\"mae\"].std(),\n",
    "        \"n_windows\": len(metrics_df),\n",
    "    }\n",
    "    \n",
    "    # Drift threshold: mean + 2*std\n",
    "    baseline[\"drift_threshold_rmse\"] = baseline[\"rmse_mean\"] + 2 * baseline[\"rmse_std\"]\n",
    "    baseline[\"drift_threshold_mae\"] = baseline[\"mae_mean\"] + 2 * baseline[\"mae_std\"]\n",
    "    \n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Training and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data: 1440 rows, 2 series\n",
      "\n",
      "=== Feature Preparation ===\n",
      "Features added: ['hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'y_lag_1', 'y_lag_24']\n",
      "\n",
      "=== Cross-Validation ===\n",
      "Running CV: 3 windows, step=168h, horizon=24h\n",
      "CV results: 144 rows\n",
      "\n",
      "Leaderboard (sorted by RMSE):\n",
      "        model      rmse       mae  coverage_80  coverage_95\n",
      "      AutoETS  4.882920  3.763942    79.861111    93.750000\n",
      "    AutoARIMA  5.171008  4.104589    79.166667    95.138889\n",
      "   MSTL_ARIMA  6.070609  4.806524    56.944444    72.916667\n",
      "SeasonalNaive  6.327316  5.083790    80.555556    98.611111\n",
      "        index 53.896518 44.150693          NaN          NaN\n",
      "\n",
      "=== Baseline Metrics (for drift detection) ===\n",
      "Best model: MSTL_ARIMA\n",
      "RMSE: 6.07 ± 0.28\n",
      "Drift threshold: 6.63\n",
      "\n",
      "(Drift detected when current RMSE > threshold)\n"
     ]
    }
   ],
   "source": [
    "# Example run - test modeling with synthetic data\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create synthetic generation data (simulates 30 days of hourly data)\n",
    "dates = pd.date_range(\"2024-01-01\", periods=720, freq=\"h\")\n",
    "series_ids = [\"CALI_WND\", \"ERCO_WND\"]\n",
    "\n",
    "dfs = []\n",
    "for sid in series_ids:\n",
    "    # Simulate generation with daily seasonality + noise\n",
    "    y = 100 + 20 * np.sin(np.arange(720) * 2 * np.pi / 24) + np.random.normal(0, 5, 720)\n",
    "    dfs.append(pd.DataFrame({\"unique_id\": sid, \"ds\": dates, \"y\": y}))\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Synthetic data: {len(df)} rows, {df['unique_id'].nunique()} series\")\n",
    "\n",
    "print(\"\\n=== Feature Preparation ===\")\n",
    "model = RenewableForecastModel(horizon=24)\n",
    "features = model.prepare_features(df)\n",
    "print(f\"Features added: {[c for c in features.columns if c not in ['unique_id', 'ds', 'y']]}\")\n",
    "\n",
    "print(\"\\n=== Cross-Validation ===\")\n",
    "cv_results, leaderboard = model.cross_validate(df, n_windows=3, step_size=168)\n",
    "print(f\"CV results: {len(cv_results)} rows\")\n",
    "print(\"\\nLeaderboard (sorted by RMSE):\")\n",
    "print(leaderboard.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Baseline Metrics (for drift detection) ===\")\n",
    "baseline = compute_baseline_metrics(cv_results)\n",
    "print(f\"Best model: {baseline['model']}\")\n",
    "print(f\"RMSE: {baseline['rmse_mean']:.2f} ± {baseline['rmse_std']:.2f}\")\n",
    "print(f\"Drift threshold: {baseline['drift_threshold_rmse']:.2f}\")\n",
    "print(\"\\n(Drift detected when current RMSE > threshold)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 5: Database Operations\n",
    "\n",
    "**File:** `src/renewable/db.py`\n",
    "\n",
    "This module handles **persistence** of forecasts, metrics, and drift alerts.\n",
    "\n",
    "## Database Schema\n",
    "\n",
    "```\n",
    "renewable_forecasts    - Forecasts with dual intervals\n",
    "renewable_scores       - Evaluation metrics per run\n",
    "weather_features       - Weather data by region\n",
    "drift_alerts           - Drift detection history\n",
    "baseline_metrics       - Backtest baselines for thresholds\n",
    "```\n",
    "\n",
    "## Why SQLite?\n",
    "\n",
    "- **Simple**: Single file, no server needed\n",
    "- **Fast**: WAL mode for concurrent reads/writes\n",
    "- **Portable**: Easy to share or backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 5: Database Operations\n",
    "# Persistence for forecasts, metrics, and alerts\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def connect(db_path: str) -> sqlite3.Connection:\n",
    "    \"\"\"Connect to SQLite with optimized settings.\"\"\"\n",
    "    Path(db_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    con = sqlite3.connect(db_path)\n",
    "    con.execute(\"PRAGMA journal_mode=WAL;\")  # Write-Ahead Logging for performance\n",
    "    con.execute(\"PRAGMA synchronous=NORMAL;\")\n",
    "    return con\n",
    "\n",
    "\n",
    "def init_renewable_db(db_path: str) -> None:\n",
    "    \"\"\"Initialize database schema.\"\"\"\n",
    "    con = connect(db_path)\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    # Forecasts with dual prediction intervals\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS renewable_forecasts (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        run_id TEXT NOT NULL,\n",
    "        created_at TEXT NOT NULL,\n",
    "        unique_id TEXT NOT NULL,\n",
    "        region TEXT NOT NULL,\n",
    "        fuel_type TEXT NOT NULL,\n",
    "        ds TEXT NOT NULL,\n",
    "        model TEXT NOT NULL,\n",
    "        yhat REAL,\n",
    "        yhat_lo_80 REAL,\n",
    "        yhat_hi_80 REAL,\n",
    "        yhat_lo_95 REAL,\n",
    "        yhat_hi_95 REAL,\n",
    "        UNIQUE (run_id, model, unique_id, ds)\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Evaluation scores\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS renewable_scores (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        scored_at TEXT NOT NULL,\n",
    "        run_id TEXT NOT NULL,\n",
    "        unique_id TEXT NOT NULL,\n",
    "        model TEXT NOT NULL,\n",
    "        rmse REAL,\n",
    "        mae REAL,\n",
    "        coverage_80 REAL,\n",
    "        coverage_95 REAL\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Weather features\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS weather_features (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        region TEXT NOT NULL,\n",
    "        ds TEXT NOT NULL,\n",
    "        temperature_2m REAL,\n",
    "        wind_speed_10m REAL,\n",
    "        wind_speed_100m REAL,\n",
    "        direct_radiation REAL,\n",
    "        cloud_cover REAL,\n",
    "        UNIQUE (region, ds)\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Drift alerts\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS drift_alerts (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        alert_at TEXT NOT NULL,\n",
    "        run_id TEXT,\n",
    "        unique_id TEXT,\n",
    "        alert_type TEXT NOT NULL,\n",
    "        severity TEXT NOT NULL,\n",
    "        current_rmse REAL,\n",
    "        threshold_rmse REAL,\n",
    "        message TEXT\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Baseline metrics for drift detection\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS baseline_metrics (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        created_at TEXT NOT NULL,\n",
    "        unique_id TEXT NOT NULL,\n",
    "        model TEXT NOT NULL,\n",
    "        rmse_mean REAL NOT NULL,\n",
    "        rmse_std REAL NOT NULL,\n",
    "        drift_threshold_rmse REAL NOT NULL,\n",
    "        UNIQUE (unique_id, model)\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def save_forecasts(db_path: str, forecasts_df: pd.DataFrame, run_id: str, model: str = \"MSTL_ARIMA\") -> int:\n",
    "    \"\"\"Save forecasts to database.\"\"\"\n",
    "    con = connect(db_path)\n",
    "    created_at = datetime.utcnow().isoformat()\n",
    "    \n",
    "    rows = []\n",
    "    for _, row in forecasts_df.iterrows():\n",
    "        unique_id = row[\"unique_id\"]\n",
    "        parts = unique_id.split(\"_\")\n",
    "        region = parts[0] if len(parts) > 0 else \"\"\n",
    "        fuel_type = parts[1] if len(parts) > 1 else \"\"\n",
    "        \n",
    "        rows.append((\n",
    "            run_id, created_at, unique_id, region, fuel_type, str(row[\"ds\"]), model,\n",
    "            row.get(\"yhat\"), row.get(\"yhat_lo_80\"), row.get(\"yhat_hi_80\"),\n",
    "            row.get(\"yhat_lo_95\"), row.get(\"yhat_hi_95\"),\n",
    "        ))\n",
    "    \n",
    "    cur = con.cursor()\n",
    "    cur.executemany(\"\"\"\n",
    "        INSERT OR REPLACE INTO renewable_forecasts\n",
    "        (run_id, created_at, unique_id, region, fuel_type, ds, model,\n",
    "         yhat, yhat_lo_80, yhat_hi_80, yhat_lo_95, yhat_hi_95)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", rows)\n",
    "    \n",
    "    con.commit()\n",
    "    con.close()\n",
    "    return len(rows)\n",
    "\n",
    "\n",
    "def save_drift_alert(\n",
    "    db_path: str, run_id: str, unique_id: str,\n",
    "    current_rmse: float, threshold_rmse: float, severity: str = \"warning\"\n",
    ") -> None:\n",
    "    \"\"\"Save drift detection alert.\"\"\"\n",
    "    con = connect(db_path)\n",
    "    \n",
    "    alert_type = \"drift_detected\" if current_rmse > threshold_rmse else \"drift_check\"\n",
    "    message = f\"RMSE {current_rmse:.1f} {'>' if current_rmse > threshold_rmse else '<='} threshold {threshold_rmse:.1f}\"\n",
    "    \n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO drift_alerts (alert_at, run_id, unique_id, alert_type, severity, current_rmse, threshold_rmse, message)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", (datetime.utcnow().isoformat(), run_id, unique_id, alert_type, severity, current_rmse, threshold_rmse, message))\n",
    "    \n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def get_recent_forecasts(db_path: str, hours: int = 48) -> pd.DataFrame:\n",
    "    \"\"\"Get recent forecasts from database.\"\"\"\n",
    "    con = connect(db_path)\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM renewable_forecasts\n",
    "        WHERE datetime(created_at) > datetime('now', '-{hours} hours')\n",
    "        ORDER BY ds DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, con)\n",
    "    con.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_drift_alerts(db_path: str, hours: int = 24) -> pd.DataFrame:\n",
    "    \"\"\"Get recent drift alerts.\"\"\"\n",
    "    con = connect(db_path)\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM drift_alerts\n",
    "        WHERE datetime(alert_at) > datetime('now', '-{hours} hours')\n",
    "        ORDER BY alert_at DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, con)\n",
    "    con.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Database Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initializing Database ===\n",
      "Tables created: ['renewable_forecasts', 'sqlite_sequence', 'renewable_scores', 'weather_features', 'drift_alerts', 'baseline_metrics']\n",
      "\n",
      "=== Saving Test Forecasts ===\n",
      "Saved 2 forecast rows\n",
      "\n",
      "=== Saving Drift Alert ===\n",
      "Alert saved\n",
      "\n",
      "=== Retrieving Data ===\n",
      "Retrieved 2 forecasts\n",
      "Retrieved 1 alerts\n",
      "                  alert_at unique_id severity                      message\n",
      "2026-01-13T20:12:41.471328  CALI_WND  warning RMSE 150.0 > threshold 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_124040\\778705923.py:20: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"ds\": [datetime.utcnow(), datetime.utcnow() + timedelta(hours=1)],\n",
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_124040\\3387579306.py:109: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  created_at = datetime.utcnow().isoformat()\n",
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_124040\\3387579306.py:151: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"\"\", (datetime.utcnow().isoformat(), run_id, unique_id, alert_type, severity, current_rmse, threshold_rmse, message))\n"
     ]
    }
   ],
   "source": [
    "# Example run - test database operations\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    db_path = f\"{tmpdir}/test_renewable.db\"\n",
    "    \n",
    "    print(\"=== Initializing Database ===\")\n",
    "    init_renewable_db(db_path)\n",
    "    \n",
    "    # Check tables\n",
    "    con = connect(db_path)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    tables = [row[0] for row in cur.fetchall()]\n",
    "    print(f\"Tables created: {tables}\")\n",
    "    con.close()\n",
    "    \n",
    "    print(\"\\n=== Saving Test Forecasts ===\")\n",
    "    test_forecasts = pd.DataFrame({\n",
    "        \"unique_id\": [\"CALI_WND\", \"CALI_WND\"],\n",
    "        \"ds\": [datetime.utcnow(), datetime.utcnow() + timedelta(hours=1)],\n",
    "        \"yhat\": [100.0, 105.0],\n",
    "        \"yhat_lo_80\": [90.0, 95.0],\n",
    "        \"yhat_hi_80\": [110.0, 115.0],\n",
    "        \"yhat_lo_95\": [80.0, 85.0],\n",
    "        \"yhat_hi_95\": [120.0, 125.0],\n",
    "    })\n",
    "    rows = save_forecasts(db_path, test_forecasts, run_id=\"test_run\")\n",
    "    print(f\"Saved {rows} forecast rows\")\n",
    "    \n",
    "    print(\"\\n=== Saving Drift Alert ===\")\n",
    "    save_drift_alert(\n",
    "        db_path,\n",
    "        run_id=\"test_run\",\n",
    "        unique_id=\"CALI_WND\",\n",
    "        current_rmse=150.0,\n",
    "        threshold_rmse=100.0,\n",
    "        severity=\"warning\",\n",
    "    )\n",
    "    print(\"Alert saved\")\n",
    "    \n",
    "    print(\"\\n=== Retrieving Data ===\")\n",
    "    forecasts = get_recent_forecasts(db_path)\n",
    "    print(f\"Retrieved {len(forecasts)} forecasts\")\n",
    "    \n",
    "    alerts = get_drift_alerts(db_path)\n",
    "    print(f\"Retrieved {len(alerts)} alerts\")\n",
    "    print(alerts[[\"alert_at\", \"unique_id\", \"severity\", \"message\"]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 6: Pipeline Tasks\n",
    "\n",
    "**File:** `src/renewable/tasks.py`\n",
    "\n",
    "This module orchestrates the complete pipeline:\n",
    "\n",
    "1. **Fetch generation data** from EIA\n",
    "2. **Fetch weather data** from Open-Meteo\n",
    "3. **Train models** with cross-validation\n",
    "4. **Generate forecasts** with prediction intervals\n",
    "5. **Compute drift metrics** vs baseline\n",
    "\n",
    "## Key Feature: Adaptive CV\n",
    "\n",
    "Cross-validation requires sufficient data:\n",
    "```\n",
    "Minimum rows = horizon + (n_windows × step_size)\n",
    "```\n",
    "\n",
    "For short series, we **adapt** the CV settings automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 6: Pipeline Tasks\n",
    "# Orchestrates the complete forecasting pipeline\n",
    "\n",
    "from datetime import timezone\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RenewablePipelineConfig:\n",
    "    \"\"\"Configuration for the renewable forecasting pipeline.\"\"\"\n",
    "    \n",
    "    # Data parameters\n",
    "    regions: list[str] = field(default_factory=lambda: [\"CALI\", \"ERCO\", \"MISO\"])\n",
    "    fuel_types: list[str] = field(default_factory=lambda: [\"WND\", \"SUN\"])\n",
    "    start_date: str = \"\"\n",
    "    end_date: str = \"\"\n",
    "    lookback_days: int = 30\n",
    "    \n",
    "    # Forecast parameters\n",
    "    horizon: int = 24\n",
    "    confidence_levels: tuple[int, int] = (80, 95)\n",
    "    \n",
    "    # CV parameters\n",
    "    cv_windows: int = 5\n",
    "    cv_step_size: int = 168  # 1 week\n",
    "    \n",
    "    # Output paths\n",
    "    data_dir: str = \"data/renewable\"\n",
    "    overwrite: bool = False\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Set default dates if not provided.\"\"\"\n",
    "        if not self.end_date:\n",
    "            self.end_date = datetime.now(timezone.utc).strftime(\"%Y-%m-%d\")\n",
    "        if not self.start_date:\n",
    "            end = datetime.strptime(self.end_date, \"%Y-%m-%d\")\n",
    "            start = end - timedelta(days=self.lookback_days)\n",
    "            self.start_date = start.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    def generation_path(self) -> Path:\n",
    "        return Path(self.data_dir) / \"generation.parquet\"\n",
    "    \n",
    "    def weather_path(self) -> Path:\n",
    "        return Path(self.data_dir) / \"weather.parquet\"\n",
    "    \n",
    "    def forecasts_path(self) -> Path:\n",
    "        return Path(self.data_dir) / \"forecasts.parquet\"\n",
    "\n",
    "\n",
    "def run_full_pipeline(config: RenewablePipelineConfig) -> dict:\n",
    "    \"\"\"Run the complete renewable forecasting pipeline.\n",
    "    \n",
    "    Steps:\n",
    "    1. Fetch generation data from EIA\n",
    "    2. Fetch weather data from Open-Meteo\n",
    "    3. Train models with adaptive cross-validation\n",
    "    4. Generate forecasts with prediction intervals\n",
    "    \"\"\"\n",
    "    print(f\"Pipeline: {config.start_date} to {config.end_date}\")\n",
    "    print(f\"Regions: {config.regions}\")\n",
    "    print(f\"Fuel types: {config.fuel_types}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Fetch generation (or use cached)\n",
    "    generation_path = config.generation_path()\n",
    "    if generation_path.exists() and not config.overwrite:\n",
    "        print(f\"\\n[Step 1] Loading cached generation data\")\n",
    "        generation_df = pd.read_parquet(generation_path)\n",
    "    else:\n",
    "        print(f\"\\n[Step 1] Fetching generation data from EIA...\")\n",
    "        fetcher = EIARenewableFetcher()\n",
    "        all_dfs = []\n",
    "        for fuel_type in config.fuel_types:\n",
    "            df = fetcher.fetch_all_regions(\n",
    "                fuel_type=fuel_type,\n",
    "                start_date=config.start_date,\n",
    "                end_date=config.end_date,\n",
    "                regions=config.regions,\n",
    "            )\n",
    "            all_dfs.append(df)\n",
    "        generation_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        generation_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        generation_df.to_parquet(generation_path, index=False)\n",
    "    \n",
    "    results[\"generation_rows\"] = len(generation_df)\n",
    "    results[\"series_count\"] = generation_df[\"unique_id\"].nunique()\n",
    "    print(f\"Generation: {results['generation_rows']} rows, {results['series_count']} series\")\n",
    "    \n",
    "    # Step 2: Fetch weather (or use cached)\n",
    "    weather_path = config.weather_path()\n",
    "    if weather_path.exists() and not config.overwrite:\n",
    "        print(f\"\\n[Step 2] Loading cached weather data\")\n",
    "        weather_df = pd.read_parquet(weather_path)\n",
    "    else:\n",
    "        print(f\"\\n[Step 2] Fetching weather data from Open-Meteo...\")\n",
    "        weather_api = OpenMeteoRenewable()\n",
    "        weather_df = weather_api.fetch_all_regions_historical(\n",
    "            regions=config.regions,\n",
    "            start_date=config.start_date,\n",
    "            end_date=config.end_date,\n",
    "        )\n",
    "        weather_df.to_parquet(weather_path, index=False)\n",
    "    \n",
    "    results[\"weather_rows\"] = len(weather_df)\n",
    "    print(f\"Weather: {results['weather_rows']} rows\")\n",
    "    \n",
    "    # Step 3: Train with adaptive CV\n",
    "    print(f\"\\n[Step 3] Training models with cross-validation...\")\n",
    "    model = RenewableForecastModel(\n",
    "        horizon=config.horizon,\n",
    "        confidence_levels=config.confidence_levels,\n",
    "    )\n",
    "    \n",
    "    # Adaptive CV settings based on data length\n",
    "    min_series_len = generation_df.groupby(\"unique_id\").size().min()\n",
    "    available_for_cv = min_series_len - config.horizon\n",
    "    \n",
    "    step_size = min(config.cv_step_size, max(24, available_for_cv // 3))\n",
    "    n_windows = min(config.cv_windows, max(2, available_for_cv // step_size))\n",
    "    \n",
    "    print(f\"Adaptive CV: {n_windows} windows, step={step_size}h (min_series={min_series_len} rows)\")\n",
    "    \n",
    "    cv_results, leaderboard = model.cross_validate(\n",
    "        df=generation_df,\n",
    "        weather_df=weather_df,\n",
    "        n_windows=n_windows,\n",
    "        step_size=step_size,\n",
    "    )\n",
    "    \n",
    "    best_model = leaderboard.iloc[0][\"model\"]\n",
    "    baseline = compute_baseline_metrics(cv_results, model_name=best_model)\n",
    "    \n",
    "    results[\"best_model\"] = best_model\n",
    "    results[\"best_rmse\"] = float(leaderboard.iloc[0][\"rmse\"])\n",
    "    results[\"baseline\"] = baseline\n",
    "    print(f\"Best model: {best_model}, RMSE: {results['best_rmse']:.1f}\")\n",
    "    \n",
    "    # Step 4: Generate forecasts\n",
    "    print(f\"\\n[Step 4] Generating {config.horizon}h forecasts...\")\n",
    "    model.fit(generation_df, weather_df)\n",
    "    forecasts = model.predict()\n",
    "    \n",
    "    forecasts_path = config.forecasts_path()\n",
    "    forecasts.to_parquet(forecasts_path, index=False)\n",
    "    \n",
    "    results[\"forecast_rows\"] = len(forecasts)\n",
    "    print(f\"Forecasts saved: {results['forecast_rows']} rows\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Running the Full Pipeline\n",
    "\n",
    "This example runs the complete pipeline with synthetic data (to avoid API calls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running Pipeline with Synthetic Data ===\n",
      "Synthetic generation: 720 rows, 2 series\n",
      "Synthetic weather: 720 rows\n",
      "\n",
      "--- Training and Cross-Validation ---\n",
      "Running CV: 3 windows, step=72h, horizon=24h\n",
      "\n",
      "Model Leaderboard:\n",
      "        model      rmse       mae  coverage_80  coverage_95\n",
      "      AutoETS 10.277663  8.030556    75.694444    96.527778\n",
      "    AutoARIMA 10.620644  8.273038    79.166667    95.833333\n",
      "SeasonalNaive 13.564617 10.646426    83.333333    95.833333\n",
      "   MSTL_ARIMA 14.122738 10.984680    34.722222    56.944444\n",
      "        index 57.895321 47.814595          NaN          NaN\n",
      "\n",
      "--- Generating Forecasts ---\n",
      "Model fit: 720 rows, 2 series\n",
      "Predictions generated: 48 rows, 24h horizon\n",
      "\n",
      "Forecast shape: (48, 28)\n",
      "Columns: ['index', 'unique_id', 'ds', 'AutoARIMA', 'AutoARIMA-lo-95', 'AutoARIMA-lo-80', 'AutoARIMA-hi-80', 'AutoARIMA-hi-95', 'SeasonalNaive', 'SeasonalNaive-lo-80', 'SeasonalNaive-lo-95', 'SeasonalNaive-hi-80', 'SeasonalNaive-hi-95', 'AutoETS', 'AutoETS-lo-95', 'AutoETS-lo-80', 'AutoETS-hi-80', 'AutoETS-hi-95', 'MSTL_ARIMA', 'MSTL_ARIMA-lo-95', 'MSTL_ARIMA-lo-80', 'MSTL_ARIMA-hi-80', 'MSTL_ARIMA-hi-95', 'yhat', 'yhat_lo_80', 'yhat_hi_80', 'yhat_lo_95', 'yhat_hi_95']\n",
      "\n",
      "Sample forecasts:\n",
      "unique_id                  ds       yhat  yhat_lo_80  yhat_hi_80\n",
      " CALI_WND 2024-01-16 00:00:00  95.900289   87.827969  103.972608\n",
      " CALI_WND 2024-01-16 01:00:00 101.007711   92.934154  109.081268\n",
      " CALI_WND 2024-01-16 02:00:00 116.013987  107.873635  124.154339\n",
      " CALI_WND 2024-01-16 03:00:00 125.488752  117.319643  133.657860\n",
      " CALI_WND 2024-01-16 04:00:00 117.850500  109.674333  126.026667\n",
      " CALI_WND 2024-01-16 05:00:00 125.867616  117.690097  134.045135\n",
      " CALI_WND 2024-01-16 06:00:00 129.236563  121.058821  137.414306\n",
      " CALI_WND 2024-01-16 07:00:00 127.714706  119.536930  135.892482\n",
      " CALI_WND 2024-01-16 08:00:00 132.301971  124.124191  140.479752\n",
      " CALI_WND 2024-01-16 09:00:00 120.015605  111.837824  128.193386\n"
     ]
    }
   ],
   "source": [
    "# Example run - demonstrate pipeline with synthetic data\n",
    "\n",
    "print(\"=== Running Pipeline with Synthetic Data ===\")\n",
    "\n",
    "# Create synthetic data (simulates what the pipeline would fetch)\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(\"2024-01-01\", periods=360, freq=\"h\")  # 15 days\n",
    "\n",
    "# Synthetic generation data\n",
    "generation_data = []\n",
    "for region in [\"CALI\", \"ERCO\"]:\n",
    "    for fuel in [\"WND\"]:\n",
    "        unique_id = f\"{region}_{fuel}\"\n",
    "        # Simulate generation with daily pattern\n",
    "        y = 100 + 30 * np.sin(np.arange(360) * 2 * np.pi / 24) + np.random.normal(0, 10, 360)\n",
    "        for i, date in enumerate(dates):\n",
    "            generation_data.append({\"unique_id\": unique_id, \"ds\": date, \"y\": max(0, y[i])})\n",
    "\n",
    "generation_df = pd.DataFrame(generation_data)\n",
    "print(f\"Synthetic generation: {len(generation_df)} rows, {generation_df['unique_id'].nunique()} series\")\n",
    "\n",
    "# Synthetic weather data\n",
    "weather_data = []\n",
    "for region in [\"CALI\", \"ERCO\"]:\n",
    "    for i, date in enumerate(dates):\n",
    "        weather_data.append({\n",
    "            \"ds\": date,\n",
    "            \"region\": region,\n",
    "            \"temperature_2m\": 15 + 10 * np.sin(i * 2 * np.pi / 24),\n",
    "            \"wind_speed_10m\": 5 + 3 * np.random.random(),\n",
    "            \"wind_speed_100m\": 8 + 4 * np.random.random(),\n",
    "            \"direct_radiation\": max(0, 500 * np.sin((date.hour - 6) * np.pi / 12)) if 6 < date.hour < 18 else 0,\n",
    "        })\n",
    "\n",
    "weather_df = pd.DataFrame(weather_data)\n",
    "print(f\"Synthetic weather: {len(weather_df)} rows\")\n",
    "\n",
    "# Run model training and forecasting\n",
    "print(\"\\n--- Training and Cross-Validation ---\")\n",
    "model = RenewableForecastModel(horizon=24, confidence_levels=(80, 95))\n",
    "\n",
    "# Adaptive CV for our short series\n",
    "cv_results, leaderboard = model.cross_validate(\n",
    "    df=generation_df,\n",
    "    weather_df=weather_df,\n",
    "    n_windows=3,\n",
    "    step_size=72,\n",
    ")\n",
    "\n",
    "print(\"\\nModel Leaderboard:\")\n",
    "print(leaderboard.to_string(index=False))\n",
    "\n",
    "print(\"\\n--- Generating Forecasts ---\")\n",
    "model.fit(generation_df, weather_df)\n",
    "forecasts = model.predict()\n",
    "\n",
    "print(f\"\\nForecast shape: {forecasts.shape}\")\n",
    "print(f\"Columns: {forecasts.columns.tolist()}\")\n",
    "print(\"\\nSample forecasts:\")\n",
    "print(forecasts[[\"unique_id\", \"ds\", \"yhat\", \"yhat_lo_80\", \"yhat_hi_80\"]].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 7: End-to-End Demonstration\n",
    "\n",
    "Let's tie it all together with a complete workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RENEWABLE ENERGY FORECASTING - END-TO-END DEMO\n",
      "============================================================\n",
      "\n",
      "1. CONFIGURATION\n",
      "----------------------------------------\n",
      "Regions available: ['CALI', 'CAR', 'CENT', 'ERCO', 'FLA']... (15 total)\n",
      "Fuel types: ['WND', 'SUN']\n",
      "\n",
      "2. DATA SUMMARY\n",
      "----------------------------------------\n",
      "Generation series: ['CALI_WND', 'ERCO_WND']\n",
      "Date range: 2024-01-01 00:00:00 to 2024-01-15 23:00:00\n",
      "Weather features: ['temperature_2m', 'wind_speed_10m', 'wind_speed_100m', 'direct_radiation']\n",
      "\n",
      "3. MODEL PERFORMANCE\n",
      "----------------------------------------\n",
      "Best model: AutoETS\n",
      "RMSE: 10.28\n",
      "MAE: 8.03\n",
      "80% Coverage: 75.69444444444444\n",
      "95% Coverage: 96.52777777777779\n",
      "\n",
      "4. FORECAST OUTPUT\n",
      "----------------------------------------\n",
      "Horizon: 24 hours\n",
      "Total predictions: 48\n",
      "\n",
      "Sample forecast for CALI_WND:\n",
      "                 ds       yhat  yhat_lo_80  yhat_hi_80\n",
      "2024-01-16 00:00:00  95.900289   87.827969  103.972608\n",
      "2024-01-16 01:00:00 101.007711   92.934154  109.081268\n",
      "2024-01-16 02:00:00 116.013987  107.873635  124.154339\n",
      "2024-01-16 03:00:00 125.488752  117.319643  133.657860\n",
      "2024-01-16 04:00:00 117.850500  109.674333  126.026667\n",
      "2024-01-16 05:00:00 125.867616  117.690097  134.045135\n",
      "\n",
      "5. DRIFT DETECTION\n",
      "----------------------------------------\n",
      "Baseline RMSE: 10.25 ± 0.93\n",
      "Drift threshold: 12.11\n",
      "\n",
      "(Production system would alert when RMSE exceeds threshold)\n",
      "\n",
      "============================================================\n",
      "DEMO COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Complete end-to-end demonstration\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RENEWABLE ENERGY FORECASTING - END-TO-END DEMO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Configuration\n",
    "print(\"\\n1. CONFIGURATION\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Regions available: {list_regions()[:5]}... ({len(REGIONS)} total)\")\n",
    "print(f\"Fuel types: {list(FUEL_TYPES.keys())}\")\n",
    "\n",
    "# 2. Data Summary\n",
    "print(\"\\n2. DATA SUMMARY\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Generation series: {generation_df['unique_id'].unique().tolist()}\")\n",
    "print(f\"Date range: {generation_df['ds'].min()} to {generation_df['ds'].max()}\")\n",
    "print(f\"Weather features: {[c for c in weather_df.columns if c not in ['ds', 'region']]}\")\n",
    "\n",
    "# 3. Model Performance\n",
    "print(\"\\n3. MODEL PERFORMANCE\")\n",
    "print(\"-\"*40)\n",
    "best_model = leaderboard.iloc[0]\n",
    "print(f\"Best model: {best_model['model']}\")\n",
    "print(f\"RMSE: {best_model['rmse']:.2f}\")\n",
    "print(f\"MAE: {best_model['mae']:.2f}\")\n",
    "if 'coverage_80' in leaderboard.columns:\n",
    "    print(f\"80% Coverage: {best_model.get('coverage_80', 'N/A')}\")\n",
    "    print(f\"95% Coverage: {best_model.get('coverage_95', 'N/A')}\")\n",
    "\n",
    "# 4. Forecast Output\n",
    "print(\"\\n4. FORECAST OUTPUT\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Horizon: 24 hours\")\n",
    "print(f\"Total predictions: {len(forecasts)}\")\n",
    "print(f\"\\nSample forecast for {forecasts['unique_id'].iloc[0]}:\")\n",
    "sample = forecasts[forecasts['unique_id'] == forecasts['unique_id'].iloc[0]].head(6)\n",
    "print(sample[[\"ds\", \"yhat\", \"yhat_lo_80\", \"yhat_hi_80\"]].to_string(index=False))\n",
    "\n",
    "# 5. Drift Detection Setup\n",
    "print(\"\\n5. DRIFT DETECTION\")\n",
    "print(\"-\"*40)\n",
    "baseline = compute_baseline_metrics(cv_results, model_name=best_model['model'])\n",
    "print(f\"Baseline RMSE: {baseline['rmse_mean']:.2f} ± {baseline['rmse_std']:.2f}\")\n",
    "print(f\"Drift threshold: {baseline['drift_threshold_rmse']:.2f}\")\n",
    "print(\"\\n(Production system would alert when RMSE exceeds threshold)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEMO COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 8: Dashboard\n",
    "\n",
    "**File:** `src/renewable/dashboard.py`\n",
    "\n",
    "The Streamlit dashboard provides:\n",
    "- **Forecast visualization** with prediction intervals\n",
    "- **Drift monitoring** and alerts\n",
    "- **Coverage analysis** (nominal vs empirical)\n",
    "- **Weather features** by region\n",
    "\n",
    "## Running the Dashboard\n",
    "\n",
    "```bash\n",
    "streamlit run src/renewable/dashboard.py\n",
    "```\n",
    "\n",
    "The dashboard will:\n",
    "1. Load forecasts from `data/renewable/forecasts.parquet`\n",
    "2. Display interactive charts with Plotly\n",
    "3. Show drift alerts from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Key Dashboard Components:\n",
      "\n",
      "## 1. Forecast Tab\n",
      "- Interactive line chart with 80% and 95% prediction intervals\n",
      "- Series selector (e.g., CALI_WND, ERCO_SUN)\n",
      "- Data table with forecast details\n",
      "\n",
      "## 2. Drift Monitor Tab  \n",
      "- Real-time drift status (stable/warning/critical)\n",
      "- Alert history with timestamps\n",
      "- RMSE vs threshold visualization\n",
      "\n",
      "## 3. Coverage Tab\n",
      "- Nominal vs empirical coverage comparison\n",
      "- Bar chart showing calibration quality\n",
      "- Per-series coverage breakdown\n",
      "\n",
      "## 4. Weather Tab\n",
      "- Wind speed at 10m and 100m by region\n",
      "- Solar radiation patterns\n",
      "- Cloud cover trends\n",
      "\n",
      "\n",
      "==================================================\n",
      "To launch the dashboard, run:\n",
      "==================================================\n",
      "\n",
      "  streamlit run src/renewable/dashboard.py\n",
      "\n",
      "The dashboard will open in your browser.\n"
     ]
    }
   ],
   "source": [
    "# Dashboard code preview (runs with Streamlit, not in Jupyter)\n",
    "\n",
    "dashboard_preview = '''\n",
    "# Key Dashboard Components:\n",
    "\n",
    "## 1. Forecast Tab\n",
    "- Interactive line chart with 80% and 95% prediction intervals\n",
    "- Series selector (e.g., CALI_WND, ERCO_SUN)\n",
    "- Data table with forecast details\n",
    "\n",
    "## 2. Drift Monitor Tab  \n",
    "- Real-time drift status (stable/warning/critical)\n",
    "- Alert history with timestamps\n",
    "- RMSE vs threshold visualization\n",
    "\n",
    "## 3. Coverage Tab\n",
    "- Nominal vs empirical coverage comparison\n",
    "- Bar chart showing calibration quality\n",
    "- Per-series coverage breakdown\n",
    "\n",
    "## 4. Weather Tab\n",
    "- Wind speed at 10m and 100m by region\n",
    "- Solar radiation patterns\n",
    "- Cloud cover trends\n",
    "'''\n",
    "\n",
    "print(dashboard_preview)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"To launch the dashboard, run:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n  streamlit run src/renewable/dashboard.py\")\n",
    "print(\"\\nThe dashboard will open in your browser.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## What We Built\n",
    "\n",
    "| Module | Purpose | Key Concept |\n",
    "|--------|---------|-------------|\n",
    "| `regions.py` | Region definitions | EIA codes + coordinates |\n",
    "| `eia_renewable.py` | Data fetching | StatsForecast format |\n",
    "| `open_meteo.py` | Weather integration | Leakage prevention |\n",
    "| `modeling.py` | Forecasting | Probabilistic intervals |\n",
    "| `db.py` | Persistence | SQLite with WAL |\n",
    "| `tasks.py` | Pipeline orchestration | Adaptive CV |\n",
    "| `dashboard.py` | Visualization | Streamlit + Plotly |\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **StatsForecast format**: `[unique_id, ds, y]` enables multi-series modeling\n",
    "2. **No MAPE for renewables**: Solar has zeros - use RMSE/MAE instead\n",
    "3. **Weather leakage**: Use forecast weather for predictions, not historical\n",
    "4. **Drift detection**: threshold = baseline_mean + 2 × baseline_std\n",
    "5. **Adaptive CV**: Adjust window count for short time series\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Get an EIA API key and run with real data\n",
    "2. Launch the dashboard: `streamlit run src/renewable/dashboard.py`\n",
    "3. Experiment with different regions and fuel types\n",
    "4. Set up scheduled pipeline runs for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying module imports...\n",
      "All imports successful!\n",
      "\n",
      "Available regions: 15\n",
      "Available fuel types: ['WND', 'SUN']\n"
     ]
    }
   ],
   "source": [
    "# Final test - verify all imports work\n",
    "\n",
    "print(\"Verifying module imports...\")\n",
    "\n",
    "try:\n",
    "    from src.renewable import (\n",
    "        REGIONS,\n",
    "        FUEL_TYPES,\n",
    "        EIARenewableFetcher,\n",
    "        OpenMeteoRenewable,\n",
    "        RenewableForecastModel,\n",
    "        RenewablePipelineConfig,\n",
    "        init_renewable_db,\n",
    "    )\n",
    "    print(\"All imports successful!\")\n",
    "    print(f\"\\nAvailable regions: {len(REGIONS)}\")\n",
    "    print(f\"Available fuel types: {list(FUEL_TYPES.keys())}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"\\nMake sure you're running from the project root.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atsaf (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
